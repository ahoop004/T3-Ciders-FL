{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6ad17f",
   "metadata": {},
   "source": [
    "# Adversarial Federated Learning Lab\n",
    "\n",
    "This lab mirrors the structure of earlier modules: you will first train a clean MobileNetV3 FedAvg model on CIFAR-10, then escalate into surrogate-driven poisoning attacks and compare the outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2b75dc",
   "metadata": {},
   "source": [
    "> Duplicate this notebook if you want to keep a personal record of experiments or notes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cfba9f",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "Locate the repository root, register it on `sys.path`, and import the Module 4 utilities used throughout the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e15181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from importlib import import_module\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if not (PROJECT_ROOT / \"4_Adversarial_FL\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "PACKAGE_ROOT = PROJECT_ROOT / \"4_Adversarial_FL\"\n",
    "\n",
    "if not PACKAGE_ROOT.exists():\n",
    "    raise RuntimeError(\"Run this notebook from the repo root or inside 4_Adversarial_FL.\")\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "load_data_module = import_module(\"4_Adversarial_FL.load_data_for_clients\")\n",
    "client_module = import_module(\"4_Adversarial_FL.client\")\n",
    "model_module = import_module(\"4_Adversarial_FL.model\")\n",
    "utils_module = import_module(\"4_Adversarial_FL.util_functions\")\n",
    "attacks_module = import_module(\"4_Adversarial_FL.attacks\")\n",
    "\n",
    "Client = client_module.Client\n",
    "MobileNetV3Transfer = model_module.MobileNetV3Transfer\n",
    "MobileNetV2Transfer = model_module.MobileNetV2Transfer\n",
    "set_seed = utils_module.set_seed\n",
    "evaluate_fn = utils_module.evaluate_fn\n",
    "resolve_callable = utils_module.resolve_callable\n",
    "dist_data_per_client = load_data_module.dist_data_per_client\n",
    "get_attack = attacks_module.get_attack\n",
    "\n",
    "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "\n",
    "def denormalize_batch(batch: torch.Tensor) -> torch.Tensor:\n",
    "    return batch * IMAGENET_STD.to(batch.device) + IMAGENET_MEAN.to(batch.device)\n",
    "\n",
    "\n",
    "def normalize_batch(batch: torch.Tensor) -> torch.Tensor:\n",
    "    return (batch - IMAGENET_MEAN.to(batch.device)) / IMAGENET_STD.to(batch.device)\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using project root: {PROJECT_ROOT}\")\n",
    "print(f\"Device detected: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e0534c",
   "metadata": {},
   "source": [
    "## 2. Clean FedAvg Baseline\n",
    "\n",
    "Replicate the honest training workflow from the earlier modules: run MobileNetV3 with realistic client counts, rounds, and epochs on CIFAR-10. This establishes the reference trajectory before any adversarial behaviour is introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c75d9",
   "metadata": {},
   "source": [
    "### 2.1 Configure baseline hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42c971",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_config = {\n",
    "    \"seed\": 27,\n",
    "    \"data\": {\n",
    "        \"dataset_path\": \"./data\",\n",
    "        \"dataset_name\": \"CIFAR10\",\n",
    "        \"non_iid_per\": 0.2,\n",
    "    },\n",
    "    \"federated\": {\n",
    "        \"num_clients\": 50,\n",
    "        \"fraction_clients\": 0.2,\n",
    "        \"num_rounds\": 10,\n",
    "        \"num_epochs\": 2,\n",
    "        \"batch_size\": 64,\n",
    "        \"local_lr\": 0.05,\n",
    "        \"criterion\": \"torch.nn.CrossEntropyLoss\",\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"num_classes\": 10,\n",
    "    },\n",
    "}\n",
    "baseline_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7109a471",
   "metadata": {},
   "source": [
    "Bump `num_rounds` or `num_epochs` after you validate the workflow; the defaults provide a realistic yet tractable run for CPU-only environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2566a500",
   "metadata": {},
   "source": [
    "### 2.2 Prepare CIFAR-10 client loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf6785",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(baseline_config[\"seed\"])\n",
    "\n",
    "CLIENT_LOADERS, TEST_LOADER = dist_data_per_client(\n",
    "    data_path=baseline_config[\"data\"][\"dataset_path\"],\n",
    "    dataset_name=baseline_config[\"data\"][\"dataset_name\"],\n",
    "    num_clients=baseline_config[\"federated\"][\"num_clients\"],\n",
    "    batch_size=baseline_config[\"federated\"][\"batch_size\"],\n",
    "    non_iid_per=baseline_config[\"data\"][\"non_iid_per\"],\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "len(CLIENT_LOADERS), len(TEST_LOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be58e77e",
   "metadata": {},
   "source": [
    "_(Optional)_ Inspect a batch to sanity-check shapes and label balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c73dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_images, sample_labels = next(iter(CLIENT_LOADERS[0]))\n",
    "# sample_images.shape, sample_labels[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a6ef15",
   "metadata": {},
   "source": [
    "### 2.3 Build honest clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "criterion_path = baseline_config[\"federated\"][\"criterion\"]\n",
    "honest_criterion = resolve_callable(criterion_path)()\n",
    "\n",
    "\n",
    "def build_honest_clients() -> list[Client]:\n",
    "    clients = []\n",
    "    for idx, loader in enumerate(CLIENT_LOADERS):\n",
    "        clients.append(\n",
    "            Client(\n",
    "                client_id=idx,\n",
    "                local_data=loader,\n",
    "                device=DEVICE,\n",
    "                num_epochs=baseline_config[\"federated\"][\"num_epochs\"],\n",
    "                criterion=honest_criterion,\n",
    "                lr=baseline_config[\"federated\"][\"local_lr\"],\n",
    "            )\n",
    "        )\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa7411",
   "metadata": {},
   "source": [
    "### 2.4 FedAvg training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953db9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def run_fedavg_rounds(clients, config, label: str, *, verbose: bool = True, malicious_ids: list[int] | None = None):\n",
    "    num_clients = len(clients)\n",
    "    num_rounds = config[\"federated\"][\"num_rounds\"]\n",
    "    fraction = config[\"federated\"][\"fraction_clients\"]\n",
    "    model_kwargs = {\n",
    "        \"num_classes\": config[\"model\"][\"num_classes\"],\n",
    "    }\n",
    "    eval_criterion = resolve_callable(config[\"federated\"][\"criterion\"])()\n",
    "\n",
    "    malicious_set = set(malicious_ids or [])\n",
    "    history = []\n",
    "    metrics = {\"loss\": [], \"accuracy\": []}\n",
    "    global_model = MobileNetV3Transfer(**model_kwargs).to(DEVICE)\n",
    "\n",
    "    for round_idx in range(num_rounds):\n",
    "        set_seed(config[\"seed\"] + round_idx)\n",
    "        num_sampled = max(1, int(math.ceil(fraction * num_clients)))\n",
    "        sampled = sorted(np.random.choice(num_clients, size=num_sampled, replace=False).tolist())\n",
    "        active_malicious = [idx for idx in sampled if idx in malicious_set]\n",
    "        history.append(\n",
    "            {\n",
    "                \"round\": round_idx + 1,\n",
    "                \"sampled\": sampled,\n",
    "                \"malicious\": active_malicious,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        for idx in sampled:\n",
    "            client_model = MobileNetV3Transfer(**model_kwargs).to(DEVICE)\n",
    "            client_model.load_state_dict(global_model.state_dict())\n",
    "            clients[idx].x = client_model\n",
    "\n",
    "        for idx in sampled:\n",
    "            clients[idx].client_update()\n",
    "\n",
    "        avg_params = [torch.zeros_like(param, device=DEVICE) for param in global_model.parameters()]\n",
    "        with torch.no_grad():\n",
    "            for idx in sampled:\n",
    "                for avg_param, client_param in zip(avg_params, clients[idx].y.parameters()):\n",
    "                    avg_param.add_(client_param.data / len(sampled))\n",
    "            for param, avg_param in zip(global_model.parameters(), avg_params):\n",
    "                param.data.copy_(avg_param.data)\n",
    "\n",
    "        loss, acc = evaluate_fn(TEST_LOADER, global_model, eval_criterion, DEVICE)\n",
    "        metrics[\"loss\"].append(loss)\n",
    "        metrics[\"accuracy\"].append(acc)\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"[{label}] Round {round_idx + 1}: sampled={sampled} malicious={active_malicious} \"\n",
    "                f\"loss={loss:.4f} acc={acc:.2f}%\"\n",
    "            )\n",
    "\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"global_model\": global_model,\n",
    "        \"metrics\": metrics,\n",
    "        \"history\": history,\n",
    "        \"config\": config,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb85444",
   "metadata": {},
   "source": [
    "### 2.5 Execute the clean baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db5e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training clean MobileNetV3 FedAvg baseline on CIFAR-10...\")\n",
    "honest_clients = build_honest_clients()\n",
    "baseline_run = run_fedavg_rounds(honest_clients, baseline_config, label=\"Clean FedAvg\")\n",
    "print(\"Baseline training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd3c0c",
   "metadata": {},
   "source": [
    "### 2.6 Visualise clean accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702fc381",
   "metadata": {},
   "outputs": [],
   "source": [
    "if baseline_run:\n",
    "    rounds = range(1, len(baseline_run[\"metrics\"][\"accuracy\"]) + 1)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(rounds, baseline_run[\"metrics\"][\"accuracy\"], marker=\"o\", label=baseline_run[\"label\"])\n",
    "    plt.xlabel(\"Communication round\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(\"Clean FedAvg test accuracy\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(rounds, baseline_run[\"metrics\"][\"loss\"], marker=\"o\", label=baseline_run[\"label\"])\n",
    "    plt.xlabel(\"Communication round\")\n",
    "    plt.ylabel(\"Cross-entropy loss\")\n",
    "    plt.title(\"Clean FedAvg test loss\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Train the clean baseline first to unlock these plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b842f0",
   "metadata": {},
   "source": [
    "## 3. Attack Primer\n",
    "\n",
    "Before coding, recall the main threat families encountered in adversarial federated learning:\n",
    "\n",
    "- **Data poisoning**: tamper with local batches so the aggregated update nudges the global model toward attacker objectives.\n",
    "- **Model poisoning**: forge parameter updates directly (e.g., model replacement).\n",
    "- **Evasion attacks**: craft examples at inference time without modifying training.\n",
    "\n",
    "This lab focuses on *surrogate-driven data poisoning*, which blends the ideas above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc24bfd",
   "metadata": {},
   "source": [
    "## 4. White-box vs. Black-box Surrogates\n",
    "\n",
    "| Setting | Attacker knowledge | Typical strategy |\n",
    "| --- | --- | --- |\n",
    "| White-box | Full access to the victim architecture and weights | Optimise adversarial updates directly on the victim. |\n",
    "| Black-box | Only input/output queries or periodic snapshots | Train a *surrogate* model and transfer crafted examples. |\n",
    "\n",
    "Federated settings often land in between—clients observe the architecture and snapshots but rarely the entire training trace. You will emulate a black-box attacker by swapping MobileNetV3 for a closely related MobileNetV2 surrogate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eb2672",
   "metadata": {},
   "source": [
    "## 5. Train a Surrogate Model (MobileNetV2)\n",
    "\n",
    "Assume the attacker controls one client shard. Fine-tune a MobileNetV2 surrogate on that shard so it approximates the victim’s behaviour despite the architectural mismatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5732f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_config = {\n",
    "    \"client_id\": 0,\n",
    "    \"epochs\": 3,\n",
    "    \"lr\": 1e-3,\n",
    "    \"batch_size\": baseline_config[\"federated\"][\"batch_size\"],\n",
    "    \"criterion\": \"torch.nn.CrossEntropyLoss\",\n",
    "}\n",
    "\n",
    "surrogate_dataset = CLIENT_LOADERS[surrogate_config[\"client_id\"]].dataset\n",
    "surrogate_loader = DataLoader(\n",
    "    surrogate_dataset,\n",
    "    batch_size=surrogate_config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "surrogate_model = MobileNetV2Transfer(\n",
    "    pretrained=True,\n",
    "    num_classes=baseline_config[\"model\"][\"num_classes\"],\n",
    ").to(DEVICE)\n",
    "\n",
    "surrogate_optimizer = torch.optim.Adam(surrogate_model.parameters(), lr=surrogate_config[\"lr\"])\n",
    "surrogate_criterion = resolve_callable(surrogate_config[\"criterion\"])()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_SURROGATE_TRAINING = False\n",
    "\n",
    "if RUN_SURROGATE_TRAINING:\n",
    "    set_seed(baseline_config[\"seed\"])\n",
    "    surrogate_model.train()\n",
    "    for epoch in range(surrogate_config[\"epochs\"]):\n",
    "        epoch_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for images, labels in surrogate_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            surrogate_optimizer.zero_grad()\n",
    "            logits = surrogate_model(images)\n",
    "            loss = surrogate_criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            surrogate_optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * labels.size(0)\n",
    "            total += labels.size(0)\n",
    "            correct += (logits.argmax(dim=1) == labels).sum().item()\n",
    "        avg_loss = epoch_loss / max(total, 1)\n",
    "        acc = 100 * correct / max(total, 1)\n",
    "        print(f\"Epoch {epoch + 1}: loss={avg_loss:.4f} acc={acc:.2f}%\")\n",
    "else:\n",
    "    print(\"Set RUN_SURROGATE_TRAINING = True to fine-tune the surrogate model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e035264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(loader, model, description: str):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            preds = model(images).argmax(dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    acc = 100 * correct / max(total, 1)\n",
    "    print(f\"{description} accuracy: {acc:.2f}% ({correct}/{total})\")\n",
    "\n",
    "\n",
    "evaluate_model(surrogate_loader, surrogate_model, \"Surrogate (local shard)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429e0ac8",
   "metadata": {},
   "source": [
    "## 6. Craft Attacks on the Surrogate\n",
    "\n",
    "Configure an attack recipe—PGD, FGSM, or random noise—then craft adversarial batches the malicious clients will replay during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_recipe = {\n",
    "    \"type\": \"pgd\",           # options: \"pgd\", \"fgsm\", \"rand_noise\"\n",
    "    \"poison_rate\": 0.2,       # fraction of a malicious minibatch to replace\n",
    "    \"target_label\": 0,        # targeted misclassification (set to None for untargeted)\n",
    "    \"epsilon\": 0.03137255,    # 8/255 L_inf budget\n",
    "    \"step_size\": 0.00784314,  # 2/255 per step\n",
    "    \"iters\": 10,              # PGD iterations\n",
    "    \"criterion\": \"torch.nn.CrossEntropyLoss\",\n",
    "}\n",
    "\n",
    "attack_fn = get_attack(attack_recipe[\"type\"])\n",
    "attack_criterion = resolve_callable(attack_recipe[\"criterion\"])()\n",
    "\n",
    "print(\"Configured attack:\")\n",
    "attack_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184619cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_attack_labels(labels: torch.Tensor, recipe: dict) -> torch.Tensor:\n",
    "    target_label = recipe.get(\"target_label\")\n",
    "    if target_label is None:\n",
    "        return labels\n",
    "    return torch.full_like(labels, int(target_label))\n",
    "\n",
    "\n",
    "def craft_adversarial_examples(images: torch.Tensor, labels: torch.Tensor, *, surrogate, attack_fn, attack_criterion, recipe: dict) -> torch.Tensor:\n",
    "    surrogate.eval()\n",
    "    images = images.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "\n",
    "    attack_name = recipe[\"type\"].lower()\n",
    "    denorm = denormalize_batch(images)\n",
    "\n",
    "    if attack_name == \"pgd\":\n",
    "        adv_denorm = attack_fn(\n",
    "            model=surrogate,\n",
    "            criterion=attack_criterion,\n",
    "            images=denorm,\n",
    "            labels=labels,\n",
    "            eps=recipe.get(\"epsilon\", 0.03),\n",
    "            step_size=recipe.get(\"step_size\", 0.007),\n",
    "            iters=recipe.get(\"iters\", 5),\n",
    "        )\n",
    "    elif attack_name == \"fgsm\":\n",
    "        adv_denorm = attack_fn(\n",
    "            model=surrogate,\n",
    "            criterion=attack_criterion,\n",
    "            images=denorm,\n",
    "            labels=labels,\n",
    "            step_size=recipe.get(\"step_size\", 0.003),\n",
    "        )\n",
    "    else:\n",
    "        adv_denorm = attack_fn(\n",
    "            denorm,\n",
    "            step_size=recipe.get(\"step_size\", 0.003),\n",
    "        )\n",
    "\n",
    "    return normalize_batch(adv_denorm)\n",
    "\n",
    "\n",
    "def plot_clean_vs_adv(clean_batch: torch.Tensor, adv_batch: torch.Tensor, index: int = 0) -> None:\n",
    "    clean_img = denormalize_batch(clean_batch[index:index + 1]).squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    adv_img = denormalize_batch(adv_batch[index:index + 1]).squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    axes[0].imshow(np.clip(clean_img, 0, 1))\n",
    "    axes[0].set_title(\"Clean\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(np.clip(adv_img, 0, 1))\n",
    "    axes[1].set_title(\"Adversarial\")\n",
    "    axes[1].axis(\"off\")\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44607175",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = next(iter(surrogate_loader))\n",
    "clean_images, clean_labels = sample_batch\n",
    "attack_labels = prepare_attack_labels(clean_labels, attack_recipe)\n",
    "adversarial_images = craft_adversarial_examples(\n",
    "    clean_images,\n",
    "    attack_labels,\n",
    "    surrogate=surrogate_model,\n",
    "    attack_fn=attack_fn,\n",
    "    attack_criterion=attack_criterion,\n",
    "    recipe=attack_recipe,\n",
    ")\n",
    "\n",
    "plot_clean_vs_adv(clean_images, adversarial_images, index=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbebd119",
   "metadata": {},
   "source": [
    "## 7. Deploy the Attack Against the Clean Model\n",
    "\n",
    "Wrap the surrogate logic in a malicious client that poisons a fraction of its minibatches on the fly, then rerun FedAvg to observe how the global MobileNetV3 degrades relative to the clean baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c545ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrogateAttackClient(Client):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        client_id: int,\n",
    "        local_data,\n",
    "        device: torch.device,\n",
    "        num_epochs: int,\n",
    "        criterion,\n",
    "        lr: float,\n",
    "        surrogate_state,\n",
    "        attack_fn,\n",
    "        attack_criterion,\n",
    "        recipe: dict,\n",
    "        num_classes: int,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            client_id=client_id,\n",
    "            local_data=local_data,\n",
    "            device=device,\n",
    "            num_epochs=num_epochs,\n",
    "            criterion=criterion,\n",
    "            lr=lr,\n",
    "        )\n",
    "        self.recipe = recipe\n",
    "        self.attack_fn = attack_fn\n",
    "        self.attack_criterion = attack_criterion\n",
    "        self.poison_rate = float(recipe.get(\"poison_rate\", 0.0))\n",
    "        self.target_label = recipe.get(\"target_label\")\n",
    "        self.surrogate = MobileNetV2Transfer(pretrained=True, num_classes=num_classes).to(self.device)\n",
    "        self.surrogate.load_state_dict(surrogate_state)\n",
    "        self.surrogate.eval()\n",
    "\n",
    "    def client_update(self) -> None:\n",
    "        if self.x is None:\n",
    "            raise ValueError(\"Client model `x` has not been initialised by the server.\")\n",
    "\n",
    "        self.y = deepcopy(self.x).to(self.device)\n",
    "        self.y.train()\n",
    "\n",
    "        for _ in range(self.num_epochs):\n",
    "            for inputs, labels in self.data:\n",
    "                inputs = inputs.float().to(self.device)\n",
    "                labels = labels.long().to(self.device)\n",
    "\n",
    "                if self.poison_rate > 0.0:\n",
    "                    mask = torch.rand(labels.size(0), device=self.device) < self.poison_rate\n",
    "                    if mask.any():\n",
    "                        target_labels = labels[mask]\n",
    "                        if self.target_label is not None:\n",
    "                            target_labels = torch.full_like(target_labels, int(self.target_label))\n",
    "                        poisoned = craft_adversarial_examples(\n",
    "                            inputs[mask],\n",
    "                            target_labels,\n",
    "                            surrogate=self.surrogate,\n",
    "                            attack_fn=self.attack_fn,\n",
    "                            attack_criterion=self.attack_criterion,\n",
    "                            recipe=self.recipe,\n",
    "                        )\n",
    "                        inputs = inputs.clone()\n",
    "                        labels = labels.clone()\n",
    "                        inputs[mask] = poisoned\n",
    "                        labels[mask] = target_labels\n",
    "\n",
    "                outputs = self.y(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                grads = torch.autograd.grad(loss, self.y.parameters())\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for param, grad in zip(self.y.parameters(), grads):\n",
    "                        param.data -= self.lr * grad.data\n",
    "\n",
    "            if self.device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7132d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_attack_clients(recipe: dict, malicious_fraction: float, *, seed: int, surrogate_state) -> tuple[list[Client], list[int]]:\n",
    "    num_clients = len(CLIENT_LOADERS)\n",
    "    malicious_fraction = max(0.0, min(1.0, malicious_fraction))\n",
    "    num_malicious = int(np.floor(num_clients * malicious_fraction))\n",
    "    rng = np.random.default_rng(seed)\n",
    "    malicious_ids = []\n",
    "    if num_malicious > 0:\n",
    "        malicious_ids = sorted(rng.choice(num_clients, size=num_malicious, replace=False).tolist())\n",
    "\n",
    "    clients: list[Client] = []\n",
    "    attack_fn_local = get_attack(recipe[\"type\"])\n",
    "    attack_criterion_local = resolve_callable(recipe.get(\"criterion\", \"torch.nn.CrossEntropyLoss\"))()\n",
    "    for idx, loader in enumerate(CLIENT_LOADERS):\n",
    "        if idx in malicious_ids:\n",
    "            client = SurrogateAttackClient(\n",
    "                client_id=idx,\n",
    "                local_data=loader,\n",
    "                device=DEVICE,\n",
    "                num_epochs=baseline_config[\"federated\"][\"num_epochs\"],\n",
    "                criterion=honest_criterion,\n",
    "                lr=baseline_config[\"federated\"][\"local_lr\"],\n",
    "                surrogate_state=surrogate_state,\n",
    "                attack_fn=attack_fn_local,\n",
    "                attack_criterion=attack_criterion_local,\n",
    "                recipe=recipe,\n",
    "                num_classes=baseline_config[\"model\"][\"num_classes\"],\n",
    "            )\n",
    "        else:\n",
    "            client = Client(\n",
    "                client_id=idx,\n",
    "                local_data=loader,\n",
    "                device=DEVICE,\n",
    "                num_epochs=baseline_config[\"federated\"][\"num_epochs\"],\n",
    "                criterion=honest_criterion,\n",
    "                lr=baseline_config[\"federated\"][\"local_lr\"],\n",
    "            )\n",
    "        clients.append(client)\n",
    "\n",
    "    return clients, malicious_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc6848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_state = surrogate_model.state_dict()\n",
    "attack_run_config = {\n",
    "    \"malicious_fraction\": 0.2,\n",
    "    \"seed\": 2024,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc079a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_POISONED_TRAINING = False\n",
    "poisoned_run = None\n",
    "malicious_ids = []\n",
    "\n",
    "if RUN_POISONED_TRAINING:\n",
    "    attack_clients, malicious_ids = build_attack_clients(\n",
    "        attack_recipe,\n",
    "        attack_run_config[\"malicious_fraction\"],\n",
    "        seed=attack_run_config[\"seed\"],\n",
    "        surrogate_state=surrogate_state,\n",
    "    )\n",
    "    poisoned_run = run_fedavg_rounds(\n",
    "        attack_clients,\n",
    "        baseline_config,\n",
    "        label=\"Surrogate attack\",\n",
    "        malicious_ids=malicious_ids,\n",
    "    )\n",
    "    print(\"Poisoned training complete.\")\n",
    "else:\n",
    "    print(\"Enable RUN_POISONED_TRAINING to launch the adversarial run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4462ec8",
   "metadata": {},
   "source": [
    "### 7.1 Compare clean and poisoned trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58bce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if baseline_run and poisoned_run:\n",
    "    rounds = range(1, len(poisoned_run[\"metrics\"][\"accuracy\"]) + 1)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(rounds, baseline_run[\"metrics\"][\"accuracy\"], marker=\"o\", label=baseline_run[\"label\"])\n",
    "    plt.plot(rounds, poisoned_run[\"metrics\"][\"accuracy\"], marker=\"o\", label=poisoned_run[\"label\"])\n",
    "    plt.xlabel(\"Communication round\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(\"Clean vs. poisoned global accuracy\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(rounds, baseline_run[\"metrics\"][\"loss\"], marker=\"o\", label=baseline_run[\"label\"])\n",
    "    plt.plot(rounds, poisoned_run[\"metrics\"][\"loss\"], marker=\"o\", label=poisoned_run[\"label\"])\n",
    "    plt.xlabel(\"Communication round\")\n",
    "    plt.ylabel(\"Cross-entropy loss\")\n",
    "    plt.title(\"Clean vs. poisoned global loss\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Train both the clean and poisoned runs to compare metrics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a7b97",
   "metadata": {},
   "source": [
    "### 7.2 Inspect malicious participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fce2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if poisoned_run:\n",
    "    print(\"Malicious client ids:\", malicious_ids)\n",
    "    print(\"Round-by-round participation:\")\n",
    "    for record in poisoned_run[\"history\"]:\n",
    "        print(record)\n",
    "else:\n",
    "    print(\"No poisoned run to summarise yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b0688",
   "metadata": {},
   "source": [
    "## 8. Reflection Prompts\n",
    "\n",
    "- How quickly do the poisoned metrics diverge from the clean baseline?\n",
    "- What happens if you vary the malicious fraction, poison rate, or attack iterations?\n",
    "- Try alternative attacks (`fgsm`, `rand_noise`)—which transfer best to the MobileNetV3 victim?\n",
    "- Modify the surrogate training schedule or backbone to gauge how sensitive the attack is to architectural mismatch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
