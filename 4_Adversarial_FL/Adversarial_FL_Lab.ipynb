{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dca0a6cf",
   "metadata": {},
   "source": [
    "# Adversarial Federated Learning Lab\n",
    "\n",
    "This notebook complements the Module 4 overview. It mirrors the Module 3 workflow: load configuration from `lab_config.yaml`, run a clean FedAvg baseline, then layer on surrogate-driven poisoning attacks to compare outcomes.\n",
    "\n",
    "- **Config keys:** `seed`, `baseline` (data + federated hyperparameters), `surrogate` (attacker training schedule), `attack` (crafting recipe), and `attack_run` (malicious participation).\n",
    "- **Baseline algorithm:** FedAvg with MobileNetV3 backbone, pretrained weights assumed.\n",
    "- **Attack path:** train a MobileNetV2 surrogate, craft PGD/FGSM/random-noise batches, and deploy them during federated rounds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c03c8c3",
   "metadata": {},
   "source": [
    "> Duplicate this notebook if you want to keep personalised notes or custom configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d6f8a",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e567cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from importlib import import_module\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if not (PROJECT_ROOT / \"4_Adversarial_FL\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "PACKAGE_ROOT = PROJECT_ROOT / \"4_Adversarial_FL\"\n",
    "\n",
    "if not PACKAGE_ROOT.exists():\n",
    "    raise RuntimeError(\"Run this notebook from the repo root or inside 4_Adversarial_FL.\")\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "load_data_module = import_module(\"4_Adversarial_FL.load_data_for_clients\")\n",
    "client_module = import_module(\"4_Adversarial_FL.client\")\n",
    "model_module = import_module(\"4_Adversarial_FL.model\")\n",
    "utils_module = import_module(\"4_Adversarial_FL.util_functions\")\n",
    "attacks_module = import_module(\"4_Adversarial_FL.attacks\")\n",
    "\n",
    "Client = client_module.Client\n",
    "MobileNetV3Transfer = model_module.MobileNetV3Transfer\n",
    "MobileNetV2Transfer = model_module.MobileNetV2Transfer\n",
    "set_seed = utils_module.set_seed\n",
    "evaluate_fn = utils_module.evaluate_fn\n",
    "resolve_callable = utils_module.resolve_callable\n",
    "dist_data_per_client = load_data_module.dist_data_per_client\n",
    "get_attack = attacks_module.get_attack\n",
    "\n",
    "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "\n",
    "def denormalize_batch(batch: torch.Tensor) -> torch.Tensor:\n",
    "    return batch * IMAGENET_STD.to(batch.device) + IMAGENET_MEAN.to(batch.device)\n",
    "\n",
    "\n",
    "def normalize_batch(batch: torch.Tensor) -> torch.Tensor:\n",
    "    return (batch - IMAGENET_MEAN.to(batch.device)) / IMAGENET_STD.to(batch.device)\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using project root: {PROJECT_ROOT}\")\n",
    "print(f\"Device detected: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8bc156",
   "metadata": {},
   "source": [
    "## 2. Load Lab Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a65ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "CONFIG_PATH = PACKAGE_ROOT / \"lab_config.yaml\"\n",
    "with CONFIG_PATH.open() as f:\n",
    "    CONFIG = yaml.safe_load(f)\n",
    "\n",
    "SEED = CONFIG.get(\"seed\", 27)\n",
    "BASELINE_CFG = CONFIG[\"baseline\"]\n",
    "SURROGATE_CFG = CONFIG[\"surrogate\"]\n",
    "ATTACK_RECIPE = CONFIG[\"attack\"]\n",
    "ATTACK_RUN_CFG = CONFIG[\"attack_run\"]\n",
    "\n",
    "print(\"Loaded configuration from\", CONFIG_PATH)\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9295874b",
   "metadata": {},
   "source": [
    "## 3. Clean FedAvg Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee77181",
   "metadata": {},
   "source": [
    "### 3.1 Prepare data and clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED)\n",
    "\n",
    "CLIENT_LOADERS, TEST_LOADER = dist_data_per_client(\n",
    "    data_path=BASELINE_CFG[\"dataset_path\"],\n",
    "    dataset_name=BASELINE_CFG[\"dataset_name\"],\n",
    "    num_clients=BASELINE_CFG[\"num_clients\"],\n",
    "    batch_size=BASELINE_CFG[\"batch_size\"],\n",
    "    non_iid_per=BASELINE_CFG[\"non_iid_per\"],\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "criterion_path = BASELINE_CFG[\"criterion\"]\n",
    "honest_criterion = resolve_callable(criterion_path)()\n",
    "\n",
    "print(f\"Prepared {len(CLIENT_LOADERS)} client loaders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f86b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_honest_clients() -> list[Client]:\n",
    "    clients = []\n",
    "    for idx, loader in enumerate(CLIENT_LOADERS):\n",
    "        clients.append(\n",
    "            Client(\n",
    "                client_id=idx,\n",
    "                local_data=loader,\n",
    "                device=DEVICE,\n",
    "                num_epochs=BASELINE_CFG[\"num_epochs\"],\n",
    "                criterion=honest_criterion,\n",
    "                lr=BASELINE_CFG[\"local_lr\"],\n",
    "            )\n",
    "        )\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cde701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def run_fedavg_rounds(clients, config, label: str, *, verbose: bool = True, malicious_ids: list[int] | None = None):\n",
    "    num_clients = len(clients)\n",
    "    num_rounds = config[\"num_rounds\"]\n",
    "    fraction = config[\"fraction_clients\"]\n",
    "    model_kwargs = {\n",
    "        \"num_classes\": BASELINE_CFG[\"num_classes\"] if \"num_classes\" in BASELINE_CFG else 10,\n",
    "    }\n",
    "    global_lr = config.get(\"global_lr\", 1.0)\n",
    "    eval_criterion = resolve_callable(config[\"criterion\"])()\n",
    "\n",
    "    malicious_set = set(malicious_ids or [])\n",
    "    history = []\n",
    "    metrics = {\"loss\": [], \"accuracy\": []}\n",
    "    global_model = MobileNetV3Transfer(num_classes=model_kwargs[\"num_classes\"]).to(DEVICE)\n",
    "\n",
    "    for round_idx in range(num_rounds):\n",
    "        set_seed(SEED + round_idx)\n",
    "        num_sampled = max(1, int(math.ceil(fraction * num_clients)))\n",
    "        sampled = sorted(np.random.choice(num_clients, size=num_sampled, replace=False).tolist())\n",
    "        active_malicious = [idx for idx in sampled if idx in malicious_set]\n",
    "        history.append(\n",
    "            {\n",
    "                \"round\": round_idx + 1,\n",
    "                \"sampled\": sampled,\n",
    "                \"malicious\": active_malicious,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        for idx in sampled:\n",
    "            client_model = MobileNetV3Transfer(num_classes=model_kwargs[\"num_classes\"]).to(DEVICE)\n",
    "            client_model.load_state_dict(global_model.state_dict())\n",
    "            clients[idx].x = client_model\n",
    "\n",
    "        for idx in sampled:\n",
    "            clients[idx].client_update()\n",
    "\n",
    "        avg_params = [torch.zeros_like(param, device=DEVICE) for param in global_model.parameters()]\n",
    "        with torch.no_grad():\n",
    "            for idx in sampled:\n",
    "                for avg_param, client_param in zip(avg_params, clients[idx].y.parameters()):\n",
    "                    avg_param.add_(client_param.data / len(sampled))\n",
    "            for param, avg_param in zip(global_model.parameters(), avg_params):\n",
    "                param.data.add_(global_lr * (avg_param.data - param.data))\n",
    "\n",
    "        loss, acc = evaluate_fn(TEST_LOADER, global_model, eval_criterion, DEVICE)\n",
    "        metrics[\"loss\"].append(loss)\n",
    "        metrics[\"accuracy\"].append(acc)\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"[{label}] Round {round_idx + 1}: sampled={sampled} malicious={active_malicious} \"\n",
    "                f\"loss={loss:.4f} acc={acc:.2f}%\"\n",
    "            )\n",
    "\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"global_model\": global_model,\n",
    "        \"metrics\": metrics,\n",
    "        \"history\": history,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5b46c4",
   "metadata": {},
   "source": [
    "### 3.2 Train baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b7a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training clean MobileNetV3 FedAvg baseline on CIFAR-10...\")\n",
    "honest_clients = build_honest_clients()\n",
    "baseline_run = run_fedavg_rounds(honest_clients, BASELINE_CFG, label=\"Clean FedAvg\")\n",
    "print(\"Baseline training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_run(run: dict) -> dict:\n",
    "    metrics = run[\"metrics\"]\n",
    "    return {\n",
    "        \"label\": run[\"label\"],\n",
    "        \"final_loss\": metrics[\"loss\"][-1],\n",
    "        \"final_accuracy\": metrics[\"accuracy\"][-1],\n",
    "    }\n",
    "\n",
    "baseline_summary = summarise_run(baseline_run)\n",
    "baseline_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cbdb31",
   "metadata": {},
   "source": [
    "## 4. Attack Primer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e4dd4",
   "metadata": {},
   "source": [
    "Before coding, recap adversary styles encountered so far:\n",
    "\n",
    "- **Data poisoning**: malicious clients inject adversarial samples into local training batches.\n",
    "- **Model poisoning**: adversaries forge updates directly in parameter space (e.g., model replacement).\n",
    "- **Evasion attacks**: perturb inputs at inference time only.\n",
    "\n",
    "We will implement surrogate-driven data poisoning, where the attacker trains a proxy network to approximate the victim and transfers adversarial examples across architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e5c8a7",
   "metadata": {},
   "source": [
    "## 5. White-box vs. Black-box Surrogates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8813ea30",
   "metadata": {},
   "source": [
    "| Setting | Attacker knowledge | Typical strategy |\n",
    "| --- | --- | --- |\n",
    "| White-box | Full access to architecture + weights | Craft gradients directly on the victim model. |\n",
    "| Black-box | Limited to queries or snapshots | Train a surrogate model and transfer attacks via crafted batches. |\n",
    "\n",
    "In federated learning, clients often know the architecture (shared by the server) but only see periodic model states. We approximate a black-box attacker by fine-tuning MobileNetV2 while the server trains MobileNetV3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da32832d",
   "metadata": {},
   "source": [
    "## 6. Train Surrogate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_dataset = CLIENT_LOADERS[SURROGATE_CFG[\"client_id\"]].dataset\n",
    "surrogate_loader = DataLoader(\n",
    "    surrogate_dataset,\n",
    "    batch_size=SURROGATE_CFG[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "surrogate_model = MobileNetV2Transfer(\n",
    "    pretrained=True,\n",
    "    num_classes=BASELINE_CFG.get(\"num_classes\", 10),\n",
    ").to(DEVICE)\n",
    "\n",
    "surrogate_optimizer = torch.optim.Adam(surrogate_model.parameters(), lr=SURROGATE_CFG[\"lr\"])\n",
    "surrogate_criterion = resolve_callable(SURROGATE_CFG[\"criterion\"])()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87425d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fine-tuning surrogate MobileNetV2 on attacker shard...\")\n",
    "set_seed(SEED)\n",
    "surrogate_model.train()\n",
    "for epoch in range(SURROGATE_CFG[\"epochs\"]):\n",
    "    epoch_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for images, labels in surrogate_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        surrogate_optimizer.zero_grad()\n",
    "        logits = surrogate_model(images)\n",
    "        loss = surrogate_criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        surrogate_optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * labels.size(0)\n",
    "        total += labels.size(0)\n",
    "        correct += (logits.argmax(dim=1) == labels).sum().item()\n",
    "    avg_loss = epoch_loss / max(total, 1)\n",
    "    acc = 100 * correct / max(total, 1)\n",
    "    print(f\"Epoch {epoch + 1}: loss={avg_loss:.4f} acc={acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(loader, model, description: str):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            preds = model(images).argmax(dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    acc = 100 * correct / max(total, 1)\n",
    "    print(f\"{description} accuracy: {acc:.2f}% ({correct}/{total})\")\n",
    "\n",
    "\n",
    "evaluate_model(surrogate_loader, surrogate_model, \"Surrogate (local shard)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bad4fa",
   "metadata": {},
   "source": [
    "## 7. Craft Adversarial Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa78b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_fn = get_attack(ATTACK_RECIPE[\"type\"])\n",
    "attack_criterion = resolve_callable(ATTACK_RECIPE[\"criterion\"])()\n",
    "\n",
    "print(\"Configured attack recipe:\")\n",
    "ATTACK_RECIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80677f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_attack_labels(labels: torch.Tensor, recipe: dict) -> torch.Tensor:\n",
    "    target_label = recipe.get(\"target_label\")\n",
    "    if target_label is None:\n",
    "        return labels\n",
    "    return torch.full_like(labels, int(target_label))\n",
    "\n",
    "\n",
    "def craft_adversarial_examples(images: torch.Tensor, labels: torch.Tensor, *, surrogate, attack_fn, attack_criterion, recipe: dict) -> torch.Tensor:\n",
    "    surrogate.eval()\n",
    "    images = images.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "\n",
    "    attack_name = recipe[\"type\"].lower()\n",
    "    denorm = denormalize_batch(images)\n",
    "\n",
    "    if attack_name == \"pgd\":\n",
    "        adv_denorm = attack_fn(\n",
    "            model=surrogate,\n",
    "            criterion=attack_criterion,\n",
    "            images=denorm,\n",
    "            labels=labels,\n",
    "            eps=recipe.get(\"epsilon\", 0.03),\n",
    "            step_size=recipe.get(\"step_size\", 0.007),\n",
    "            iters=recipe.get(\"iters\", 5),\n",
    "        )\n",
    "    elif attack_name == \"fgsm\":\n",
    "        adv_denorm = attack_fn(\n",
    "            model=surrogate,\n",
    "            criterion=attack_criterion,\n",
    "            images=denorm,\n",
    "            labels=labels,\n",
    "            step_size=recipe.get(\"step_size\", 0.003),\n",
    "        )\n",
    "    else:\n",
    "        adv_denorm = attack_fn(\n",
    "            denorm,\n",
    "            step_size=recipe.get(\"step_size\", 0.003),\n",
    "        )\n",
    "\n",
    "    return normalize_batch(adv_denorm)\n",
    "\n",
    "\n",
    "def plot_clean_vs_adv(clean_batch: torch.Tensor, adv_batch: torch.Tensor, index: int = 0) -> None:\n",
    "    clean_img = denormalize_batch(clean_batch[index:index + 1]).squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    adv_img = denormalize_batch(adv_batch[index:index + 1]).squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    axes[0].imshow(np.clip(clean_img, 0, 1))\n",
    "    axes[0].set_title(\"Clean\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(np.clip(adv_img, 0, 1))\n",
    "    axes[1].set_title(\"Adversarial\")\n",
    "    axes[1].axis(\"off\")\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6fcd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images, sample_labels = next(iter(surrogate_loader))\n",
    "attack_labels = prepare_attack_labels(sample_labels, ATTACK_RECIPE)\n",
    "adversarial_images = craft_adversarial_examples(\n",
    "    sample_images,\n",
    "    attack_labels,\n",
    "    surrogate=surrogate_model,\n",
    "    attack_fn=attack_fn,\n",
    "    attack_criterion=attack_criterion,\n",
    "    recipe=ATTACK_RECIPE,\n",
    ")\n",
    "\n",
    "plot_clean_vs_adv(sample_images, adversarial_images, index=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d26ee7d",
   "metadata": {},
   "source": [
    "## 8. Deploy Surrogate Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef33fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrogateAttackClient(Client):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        client_id: int,\n",
    "        local_data,\n",
    "        device: torch.device,\n",
    "        num_epochs: int,\n",
    "        criterion,\n",
    "        lr: float,\n",
    "        surrogate_state,\n",
    "        attack_fn,\n",
    "        attack_criterion,\n",
    "        recipe: dict,\n",
    "        num_classes: int,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            client_id=client_id,\n",
    "            local_data=local_data,\n",
    "            device=device,\n",
    "            num_epochs=num_epochs,\n",
    "            criterion=criterion,\n",
    "            lr=lr,\n",
    "        )\n",
    "        self.recipe = recipe\n",
    "        self.attack_fn = attack_fn\n",
    "        self.attack_criterion = attack_criterion\n",
    "        self.poison_rate = float(recipe.get(\"poison_rate\", 0.0))\n",
    "        self.target_label = recipe.get(\"target_label\")\n",
    "        self.surrogate = MobileNetV2Transfer(pretrained=True, num_classes=num_classes).to(self.device)\n",
    "        self.surrogate.load_state_dict(surrogate_state)\n",
    "        self.surrogate.eval()\n",
    "\n",
    "    def client_update(self) -> None:\n",
    "        if self.x is None:\n",
    "            raise ValueError(\"Client model `x` has not been initialised by the server.\")\n",
    "\n",
    "        self.y = deepcopy(self.x).to(self.device)\n",
    "        self.y.train()\n",
    "\n",
    "        for _ in range(self.num_epochs):\n",
    "            for inputs, labels in self.data:\n",
    "                inputs = inputs.float().to(self.device)\n",
    "                labels = labels.long().to(self.device)\n",
    "\n",
    "                if self.poison_rate > 0.0:\n",
    "                    mask = torch.rand(labels.size(0), device=self.device) < self.poison_rate\n",
    "                    if mask.any():\n",
    "                        target_labels = labels[mask]\n",
    "                        if self.target_label is not None:\n",
    "                            target_labels = torch.full_like(target_labels, int(self.target_label))\n",
    "                        poisoned = craft_adversarial_examples(\n",
    "                            inputs[mask],\n",
    "                            target_labels,\n",
    "                            surrogate=self.surrogate,\n",
    "                            attack_fn=self.attack_fn,\n",
    "                            attack_criterion=self.attack_criterion,\n",
    "                            recipe=self.recipe,\n",
    "                        )\n",
    "                        inputs = inputs.clone()\n",
    "                        labels = labels.clone()\n",
    "                        inputs[mask] = poisoned\n",
    "                        labels[mask] = target_labels\n",
    "\n",
    "                outputs = self.y(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                grads = torch.autograd.grad(loss, self.y.parameters())\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for param, grad in zip(self.y.parameters(), grads):\n",
    "                        param.data -= self.lr * grad.data\n",
    "\n",
    "            if self.device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d410f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_attack_clients(recipe: dict, malicious_fraction: float, *, seed: int, surrogate_state) -> tuple[list[Client], list[int]]:\n",
    "    num_clients = len(CLIENT_LOADERS)\n",
    "    malicious_fraction = max(0.0, min(1.0, malicious_fraction))\n",
    "    num_malicious = int(np.floor(num_clients * malicious_fraction))\n",
    "    rng = np.random.default_rng(seed)\n",
    "    malicious_ids = []\n",
    "    if num_malicious > 0:\n",
    "        malicious_ids = sorted(rng.choice(num_clients, size=num_malicious, replace=False).tolist())\n",
    "\n",
    "    clients: list[Client] = []\n",
    "    attack_fn_local = get_attack(recipe[\"type\"])\n",
    "    attack_criterion_local = resolve_callable(recipe.get(\"criterion\", \"torch.nn.CrossEntropyLoss\"))()\n",
    "    for idx, loader in enumerate(CLIENT_LOADERS):\n",
    "        if idx in malicious_ids:\n",
    "            client = SurrogateAttackClient(\n",
    "                client_id=idx,\n",
    "                local_data=loader,\n",
    "                device=DEVICE,\n",
    "                num_epochs=BASELINE_CFG[\"num_epochs\"],\n",
    "                criterion=honest_criterion,\n",
    "                lr=BASELINE_CFG[\"local_lr\"],\n",
    "                surrogate_state=surrogate_state,\n",
    "                attack_fn=attack_fn_local,\n",
    "                attack_criterion=attack_criterion_local,\n",
    "                recipe=recipe,\n",
    "                num_classes=BASELINE_CFG.get(\"num_classes\", 10),\n",
    "            )\n",
    "        else:\n",
    "            client = Client(\n",
    "                client_id=idx,\n",
    "                local_data=loader,\n",
    "                device=DEVICE,\n",
    "                num_epochs=BASELINE_CFG[\"num_epochs\"],\n",
    "                criterion=honest_criterion,\n",
    "                lr=BASELINE_CFG[\"local_lr\"],\n",
    "            )\n",
    "        clients.append(client)\n",
    "\n",
    "    return clients, malicious_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6efb125",
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_state = surrogate_model.state_dict()\n",
    "print(\"Running surrogate-driven attack with malicious fraction =\", ATTACK_RUN_CFG[\"malicious_fraction\"])\n",
    "attack_clients, malicious_ids = build_attack_clients(\n",
    "    ATTACK_RECIPE,\n",
    "    ATTACK_RUN_CFG[\"malicious_fraction\"],\n",
    "    seed=ATTACK_RUN_CFG[\"seed\"],\n",
    "    surrogate_state=surrogate_state,\n",
    ")\n",
    "poisoned_run = run_fedavg_rounds(\n",
    "    attack_clients,\n",
    "    BASELINE_CFG,\n",
    "    label=\"Surrogate attack\",\n",
    "    malicious_ids=malicious_ids,\n",
    ")\n",
    "print(\"Attack training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ed77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoned_summary = summarise_run(poisoned_run)\n",
    "poisoned_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e9340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "summary_df = pd.DataFrame([baseline_summary, poisoned_summary])\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861cb08",
   "metadata": {},
   "source": [
    "### 8.1 Visualise trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = range(1, len(poisoned_run[\"metrics\"][\"accuracy\"]) + 1)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(rounds, baseline_run[\"metrics\"][\"accuracy\"], marker=\"o\", label=baseline_run[\"label\"])\n",
    "plt.plot(rounds, poisoned_run[\"metrics\"][\"accuracy\"], marker=\"o\", label=poisoned_run[\"label\"])\n",
    "plt.xlabel(\"Communication round\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Clean vs. poisoned accuracy\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(rounds, baseline_run[\"metrics\"][\"loss\"], marker=\"o\", label=baseline_run[\"label\"])\n",
    "plt.plot(rounds, poisoned_run[\"metrics\"][\"loss\"], marker=\"o\", label=poisoned_run[\"label\"])\n",
    "plt.xlabel(\"Communication round\")\n",
    "plt.ylabel(\"Cross-entropy loss\")\n",
    "plt.title(\"Clean vs. poisoned loss\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5401f44",
   "metadata": {},
   "source": [
    "### 8.2 Inspect malicious participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df04d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Malicious client ids:\", malicious_ids)\n",
    "for record in poisoned_run[\"history\"]:\n",
    "    print(record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32c94b",
   "metadata": {},
   "source": [
    "## 9. Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24271728",
   "metadata": {},
   "source": [
    "- How quickly does the poisoned run diverge from the clean baseline?\n",
    "- Which hyperparameters (poison rate, attack iterations, surrogate epochs) most influence attack success?\n",
    "- Try switching `attack.type` to `fgsm` or `rand_noise`. How transferable are those perturbations?\n",
    "- Experiment with defensive ideas (trimmed mean, robust aggregation) using the same structure to benchmark mitigations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
