{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709fa1c1",
   "metadata": {},
   "source": [
    "# Surrogate-Driven Poisoning Attack Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e62db",
   "metadata": {},
   "source": [
    "\n",
    "This notebook demonstrates how to launch and inspect the surrogate-driven poisoning attack\n",
    "introduced in **Module 4**. It mirrors the CLI scripts so you can tune hyperparameters and\n",
    "visualise the impact of adversarial clients directly in a notebook session.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6426412",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Environment setup\n",
    "\n",
    "The next cell infers the project root and ensures the `4_Adversarial_FL` package is importable.\n",
    "Adjust the path if you copied this notebook elsewhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ef902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "REPO_ROOT = (Path(\"..\").resolve().parent)\n",
    "if not (REPO_ROOT / \"4_Adversarial_FL\").exists():\n",
    "    raise RuntimeError(f\"Couldn't locate 4_Adversarial_FL from {REPO_ROOT}\")\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "REPO_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958e7343",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Load the baseline configuration\n",
    "\n",
    "The baseline YAML mirrors the template checked into `configs/`. Feel free to modify the\n",
    "returned dictionary before launching the experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15901a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from 4_Adversarial_FL.black_box_runner import load_config\n",
    "\n",
    "CONFIG_PATH = REPO_ROOT / \"4_Adversarial_FL\" / \"configs\" / \"surrogate_attack.yaml\"\n",
    "config = load_config(CONFIG_PATH)\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdafc78",
   "metadata": {},
   "source": [
    "\n",
    "## 3. (Optional) Run a small-scale experiment\n",
    "\n",
    "Set `RUN_EXPERIMENT = True` to trigger a lightweight training job inside the notebook. This\n",
    "assumes the dataset specified in the config is already downloaded. The run can take several\n",
    "minutes depending on the model backbone and dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from 4_Adversarial_FL.black_box_runner import run_from_config\n",
    "\n",
    "RUN_EXPERIMENT = False\n",
    "ARTIFACTS_DIR = REPO_ROOT / \"artifacts\"\n",
    "ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_PATH = ARTIFACTS_DIR / \"surrogate_metrics.json\"\n",
    "\n",
    "if RUN_EXPERIMENT:\n",
    "    runner = run_from_config(config)\n",
    "    results = runner.results\n",
    "    RESULTS_PATH.write_text(json.dumps(results, indent=2))\n",
    "else:\n",
    "    if RESULTS_PATH.exists():\n",
    "        results = json.loads(RESULTS_PATH.read_text())\n",
    "    else:\n",
    "        results = {\"accuracy\": [], \"loss\": []}\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdcbe7e",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Visualise accuracy and loss\n",
    "\n",
    "If you skipped execution, populate `artifacts/surrogate_metrics.json` by running the CLI script\n",
    "first: `python -m 4_Adversarial_FL.scripts.run_surrogate_attack --results artifacts/surrogate_metrics.json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3918755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rounds = list(range(1, len(results.get(\"accuracy\", [])) + 1))\n",
    "if rounds:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(rounds, results.get(\"accuracy\", []), label=\"Accuracy\")\n",
    "    plt.plot(rounds, results.get(\"loss\", []), label=\"Loss\")\n",
    "    plt.xlabel(\"Communication Round\")\n",
    "    plt.ylabel(\"Metric\")\n",
    "    plt.title(\"Surrogate Attack Metrics\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No results available yet. Run an experiment or load metrics from disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3becc8a",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Next steps\n",
    "\n",
    "- Try alternative attack strengths by editing `config['malicious']['attack']`.\n",
    "- Switch the model backbone (e.g. MobileNetV2) and compare convergence.\n",
    "- Increase `num_rounds` once you're confident the pipeline works end-to-end.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
