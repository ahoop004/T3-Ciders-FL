{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 Adversarial FL \u2013 Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Federated Baseline Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from util_functions import set_seed, evaluate_fn, run_fl\n",
    "from load_data_for_clients import dist_data_per_client\n",
    "from algos import (\n",
    "    Server,\n",
    "    ScaffoldServer,\n",
    "    FedAdamServer,\n",
    "    FedAdagradServer,\n",
    "    FedYogiServer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c18032",
   "metadata": {},
   "source": [
    "## 2. Federated Baseline Paths & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370afa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = Path(\"config.yaml\")\n",
    "if not CONFIG_PATH.exists():\n",
    "    raise FileNotFoundError(\"Could not locate config.yaml in the working directory\")\n",
    "\n",
    "with CONFIG_PATH.open() as f:\n",
    "    CONFIG = yaml.safe_load(f)\n",
    "\n",
    "global_config = CONFIG.get(\"global_config\", {})\n",
    "data_config = CONFIG.get(\"data_config\", {})\n",
    "model_config = CONFIG.get(\"model_config\", {})\n",
    "alg_configs = CONFIG.get(\"algorithms\", {})\n",
    "attack_defaults = CONFIG.get(\"attack\", {})\n",
    "\n",
    "set_seed(global_config.get(\"seed\", 42))\n",
    "AVAILABLE_ALGORITHMS = list(alg_configs)\n",
    "print(\"Loaded config from\", CONFIG_PATH.resolve())\n",
    "print(\"Available algorithms:\", AVAILABLE_ALGORITHMS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd69c4dd",
   "metadata": {},
   "source": [
    "## 3. Federated Baseline Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM_MAP = {\n",
    "    \"FedAvg\": Server,\n",
    "    \"Scaffold\": ScaffoldServer,\n",
    "    \"FedAdam\": FedAdamServer,\n",
    "    \"FedAdagrad\": FedAdagradServer,\n",
    "    \"FedYogi\": FedYogiServer,\n",
    "}\n",
    "\n",
    "missing = sorted(set(AVAILABLE_ALGORITHMS) - set(ALGORITHM_MAP))\n",
    "if missing:\n",
    "    raise KeyError(f\"No server mapping registered for: {missing}\")\n",
    "\n",
    "\n",
    "def train_server(alg_name: str, attack_cfg: dict | None = None):\n",
    "    if alg_name not in alg_configs:\n",
    "        raise ValueError(f\"Algorithm {alg_name!r} not found in configuration.\")\n",
    "\n",
    "    alg_conf = alg_configs[alg_name]\n",
    "    fed_cfg = deepcopy(alg_conf[\"fed_config\"])\n",
    "    fed_cfg[\"algorithm\"] = alg_name\n",
    "    optim_cfg = deepcopy(alg_conf.get(\"optim_config\", {}))\n",
    "    attack_cfg = deepcopy(attack_cfg or {\"malicious_fraction\": 0.0})\n",
    "\n",
    "    return run_fl(\n",
    "        ALGORITHM_MAP[alg_name],\n",
    "        global_config,\n",
    "        data_config,\n",
    "        fed_cfg,\n",
    "        model_config,\n",
    "        optim_cfg,\n",
    "        attack_cfg,\n",
    "    )\n",
    "\n",
    "\n",
    "def summarise_server(server) -> dict:\n",
    "    loss, acc = evaluate_fn(server.data, server.x, server.criterion, server.device)\n",
    "    history = server.results if hasattr(server, \"results\") else {}\n",
    "    return {\n",
    "        \"final_loss\": float(loss),\n",
    "        \"final_accuracy\": float(acc),\n",
    "        \"history\": {\n",
    "            \"loss\": list(history.get(\"loss\", [])),\n",
    "            \"accuracy\": list(history.get(\"accuracy\", [])),\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def run_one_algorithm(alg_name: str, attack_cfg: dict | None = None) -> dict:\n",
    "    server = train_server(alg_name, attack_cfg=attack_cfg)\n",
    "    summary = summarise_server(server)\n",
    "    del server\n",
    "    torch.cuda.empty_cache()\n",
    "    return summary\n",
    "\n",
    "\n",
    "def run_all_algorithms(\n",
    "    algorithms: list[str] | None = None,\n",
    "    attack_cfg: dict | None = None,\n",
    ") -> dict:\n",
    "    algorithms = algorithms or AVAILABLE_ALGORITHMS\n",
    "    results: dict[str, dict] = {}\n",
    "    for name in algorithms:\n",
    "        results[name] = run_one_algorithm(name, attack_cfg=attack_cfg)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce1878b",
   "metadata": {},
   "source": [
    "## 4. Federated Baseline Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2929a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_ALGORITHMS = [\"FedAvg\"]  \n",
    "\n",
    "baseline_results = run_all_algorithms(BASELINE_ALGORITHMS)\n",
    "baseline_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Surrogate Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attacks import get_attack\n",
    "from malicious_client import MaliciousClient\n",
    "from model import MobileNetV2Transfer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40898ff3",
   "metadata": {},
   "source": [
    "## 6. Surrogate Paths & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ffef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SURROGATE_CFG = CONFIG.get(\"surrogate\", {})\n",
    "SURROGATE_CLIENT_ID = int(SURROGATE_CFG.get(\"client_id\", 0))\n",
    "SURROGATE_SEED = SURROGATE_CFG.get(\"seed\", global_config.get(\"seed\", 42))\n",
    "\n",
    "_SURROGATE_CLIENT_LOADERS = None\n",
    "_SURROGATE_TEST_LOADER = None\n",
    "\n",
    "\n",
    "def _ensure_surrogate_data():\n",
    "    global _SURROGATE_CLIENT_LOADERS, _SURROGATE_TEST_LOADER\n",
    "    if _SURROGATE_CLIENT_LOADERS is not None and _SURROGATE_TEST_LOADER is not None:\n",
    "        return _SURROGATE_CLIENT_LOADERS, _SURROGATE_TEST_LOADER\n",
    "\n",
    "    loaders, test_loader = dist_data_per_client(\n",
    "        data_path=SURROGATE_CFG.get(\"dataset_path\", data_config.get(\"dataset_path\")),\n",
    "        dataset_name=SURROGATE_CFG.get(\"dataset_name\", data_config.get(\"dataset_name\")),\n",
    "        num_clients=SURROGATE_CFG.get(\"num_clients\", data_config.get(\"num_clients\", 50)),\n",
    "        batch_size=SURROGATE_CFG.get(\"batch_size\", data_config.get(\"batch_size\", 96)),\n",
    "        non_iid_per=SURROGATE_CFG.get(\"non_iid_per\", data_config.get(\"non_iid_per\", 0.0)),\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    _SURROGATE_CLIENT_LOADERS = loaders\n",
    "    _SURROGATE_TEST_LOADER = test_loader\n",
    "    return _SURROGATE_CLIENT_LOADERS, _SURROGATE_TEST_LOADER\n",
    "\n",
    "\n",
    "def get_surrogate_train_loader():\n",
    "    client_loaders, _ = _ensure_surrogate_data()\n",
    "    if SURROGATE_CLIENT_ID >= len(client_loaders):\n",
    "        raise IndexError(\n",
    "            f\"Surrogate client id {SURROGATE_CLIENT_ID} out of range for {len(client_loaders)} clients\"\n",
    "        )\n",
    "    return client_loaders[SURROGATE_CLIENT_ID]\n",
    "\n",
    "\n",
    "def get_surrogate_test_loader():\n",
    "    _, test_loader = _ensure_surrogate_data()\n",
    "    return test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5c8d9",
   "metadata": {},
   "source": [
    "## 7. Surrogate Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf56f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_surrogate_model(num_classes: int = 10, pretrained: bool | None = None) -> torch.nn.Module:\n",
    "    if pretrained is None:\n",
    "        pretrained = SURROGATE_CFG.get(\"pretrained\", True)\n",
    "    return MobileNetV2Transfer(pretrained=pretrained, num_classes=num_classes)\n",
    "\n",
    "\n",
    "def train_surrogate_baseline(num_epochs: int | None = None):\n",
    "    set_seed(SURROGATE_SEED)\n",
    "\n",
    "    train_loader = get_surrogate_train_loader()\n",
    "    model = build_surrogate_model(num_classes=SURROGATE_CFG.get(\"num_classes\", 10)).to(DEVICE)\n",
    "\n",
    "    criterion =torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=SURROGATE_CFG.get(\"local_lr\", 0.003),\n",
    "        weight_decay=SURROGATE_CFG.get(\"weight_decay\", 0.0),\n",
    "    )\n",
    "    epochs = num_epochs or SURROGATE_CFG.get(\"num_epochs\", 5)\n",
    "\n",
    "    history = {\"loss\": [], \"accuracy\": []}\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(DEVICE).float()\n",
    "            labels = labels.to(DEVICE).long()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / max(len(train_loader), 1)\n",
    "        epoch_acc = 100.0 * correct / max(total, 1)\n",
    "        history[\"loss\"].append(epoch_loss)\n",
    "        history[\"accuracy\"].append(epoch_acc)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}: loss={epoch_loss:.4f}, acc={epoch_acc:.2f}%\")\n",
    "\n",
    "    test_loader = get_surrogate_test_loader()\n",
    "    test_loss, test_acc = evaluate_fn(test_loader, model, criterion, DEVICE)\n",
    "\n",
    "    summary = {\n",
    "        \"history\": history,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_acc,\n",
    "    }\n",
    "\n",
    "    return model, summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa26462",
   "metadata": {},
   "source": [
    "## 8. Baseline Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a3c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_model, surrogate_summary = train_surrogate_baseline()\n",
    "\n",
    "fedavg_summary = baseline_results.get(\"FedAvg\", {})\n",
    "print(\"Federated baseline:\", fedavg_summary)\n",
    "print(\n",
    "    f\"Surrogate test metrics \u2192 loss: {surrogate_summary['test_loss']:.4f}, accuracy: {surrogate_summary['test_accuracy']:.2f}%\"\n",
    ")\n",
    "\n",
    "surrogate_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2416be",
   "metadata": {},
   "source": [
    "## 9. Attack Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e1da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attacks import get_attack, pgd_attack, fgsm_attack, random_noise_attack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125ba958",
   "metadata": {},
   "source": [
    "## 10. Attack Paths & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d003e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTACK_RAW = attack_defaults\n",
    "ATTACK_SEED = ATTACK_RAW.get(\"seed\", global_config.get(\"seed\", 42))\n",
    "BASE_MALICIOUS_FRACTION = ATTACK_RAW.get(\"malicious_fraction\", 0.0)\n",
    "\n",
    "\n",
    "def _extract_attack_params(overrides: dict | None = None) -> dict:\n",
    "    params = {\n",
    "        \"type\": ATTACK_RAW.get(\"type\", \"pgd\"),\n",
    "        \"poison_rate\": ATTACK_RAW.get(\"poison_rate\", 0.0),\n",
    "        \"target_label\": ATTACK_RAW.get(\"target_label\", 0),\n",
    "        \"epsilon\": ATTACK_RAW.get(\"epsilon\", 0.03137255),\n",
    "        \"step_size\": ATTACK_RAW.get(\"step_size\", 0.00784314),\n",
    "        \"iters\": ATTACK_RAW.get(\"iters\", 10),\n",
    "        \"criterion\": ATTACK_RAW.get(\"criterion\", \"torch.nn.CrossEntropyLoss\"),\n",
    "    }\n",
    "    schedule = ATTACK_RAW.get(\"poison_rate_schedule\")\n",
    "    if schedule:\n",
    "        params[\"poison_rate_schedule\"] = schedule\n",
    "    if overrides:\n",
    "        params.update(overrides)\n",
    "    return params\n",
    "\n",
    "\n",
    "def _extract_surrogate_params(overrides: dict | None = None) -> dict:\n",
    "    params = {\n",
    "        \"pretrained\": ATTACK_RAW.get(\"surrogate_pretrained\", True),\n",
    "        \"finetune_epochs\": ATTACK_RAW.get(\"surrogate_finetune_epochs\", 0),\n",
    "        \"lr\": ATTACK_RAW.get(\"surrogate_lr\", 1e-3),\n",
    "        \"batch_size\": ATTACK_RAW.get(\"surrogate_batch_size\", SURROGATE_CFG.get(\"batch_size\", data_config.get(\"batch_size\", 96))),\n",
    "        \"client_id\": SURROGATE_CFG.get(\"client_id\", 0),\n",
    "        \"num_classes\": SURROGATE_CFG.get(\"num_classes\", model_config.get(\"kwargs\", {}).get(\"num_classes\", 10)),\n",
    "        \"criterion\": ATTACK_RAW.get(\"criterion\", \"torch.nn.CrossEntropyLoss\"),\n",
    "    }\n",
    "    if overrides:\n",
    "        params.update(overrides)\n",
    "    return params\n",
    "\n",
    "\n",
    "def build_attack_config(*, attack_overrides: dict | None = None, surrogate_overrides: dict | None = None, malicious_fraction: float | None = None, seed: int | None = None) -> dict:\n",
    "    cfg = {\n",
    "        \"seed\": seed if seed is not None else ATTACK_SEED,\n",
    "        \"malicious_fraction\": BASE_MALICIOUS_FRACTION if malicious_fraction is None else malicious_fraction,\n",
    "        \"attack\": _extract_attack_params(attack_overrides),\n",
    "        \"surrogate\": _extract_surrogate_params(surrogate_overrides),\n",
    "    }\n",
    "    for key in (\"start_round\",):\n",
    "        if key in ATTACK_RAW:\n",
    "            cfg[key] = ATTACK_RAW[key]\n",
    "    return cfg\n",
    "\n",
    "\n",
    "ATTACK_RECIPES = {\n",
    "    \"clean\": build_attack_config(malicious_fraction=0.0, attack_overrides={\"poison_rate\": 0.0}),\n",
    "    \"pgd_default\": build_attack_config(),\n",
    "    \"fgsm_default\": build_attack_config(attack_overrides={\"type\": \"fgsm\", \"iters\": 1}),\n",
    "    \"random_noise\": build_attack_config(attack_overrides={\"type\": \"random_noise\"}),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d289b829",
   "metadata": {},
   "source": [
    "## 11. Attack Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b6870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict\n",
    "\n",
    "AttackFn = Callable[..., torch.Tensor]\n",
    "\n",
    "\n",
    "def pgd_attack(\n",
    "    model: torch.nn.Module,\n",
    "    criterion: torch.nn.Module,\n",
    "    images: torch.Tensor,\n",
    "    labels: torch.Tensor,\n",
    "    eps: float,\n",
    "    step_size: float,\n",
    "    iters: int,\n",
    "    targeted: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Projected Gradient Descent with an L-infinity constraint.\"\"\"\n",
    "    ori = images.clone().detach()\n",
    "    adv = ori.clone().detach()\n",
    "\n",
    "    for _ in range(iters):\n",
    "        adv.requires_grad_(True)\n",
    "        outputs = model(adv)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "\n",
    "        direction = -1 if targeted else 1\n",
    "        adv = adv + direction * step_size * adv.grad.sign()\n",
    "        eta = torch.clamp(adv - ori, min=-eps, max=eps)\n",
    "        adv = torch.clamp(ori + eta, 0, 1).detach()\n",
    "\n",
    "    return adv\n",
    "\n",
    "\n",
    "def fgsm_attack(\n",
    "    model: torch.nn.Module,\n",
    "    criterion: torch.nn.Module,\n",
    "    images: torch.Tensor,\n",
    "    labels: torch.Tensor,\n",
    "    step_size: float,\n",
    "    targeted: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Single gradient-sign step.\"\"\"\n",
    "    adv = images.clone().detach().requires_grad_(True)\n",
    "    loss = criterion(model(adv), labels)\n",
    "\n",
    "    model.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "\n",
    "    direction = -1 if targeted else 1\n",
    "    adv = adv + direction * step_size * adv.grad.sign()\n",
    "    return torch.clamp(adv, 0, 1).detach()\n",
    "\n",
    "\n",
    "def random_noise_attack(images: torch.Tensor, step_size: float) -> torch.Tensor:\n",
    "    \"\"\"Add random signed noise to the batch and clamp to valid bounds.\"\"\"\n",
    "    perturb = torch.randn_like(images).sign()\n",
    "    adv = images + step_size * perturb\n",
    "    return torch.clamp(adv, 0, 1).detach()\n",
    "\n",
    "\n",
    "ATTACK_FUNCTIONS: Dict[str, AttackFn] = {\n",
    "    \"pgd\": pgd_attack,\n",
    "    \"fgsm\": fgsm_attack,\n",
    "    \"random\": random_noise_attack,\n",
    "    \"random_noise\": random_noise_attack,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73b6552",
   "metadata": {},
   "source": [
    "## 12. Malicious Client Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec05b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_malicious_client(\n",
    "    attack_config: dict,\n",
    "    *,\n",
    "    local_loader=None,\n",
    "    surrogate=None,\n",
    "    num_epochs: int = 0,\n",
    "    lr: float | None = None,\n",
    "):\n",
    "    \"\"\"Helper to instantiate a MaliciousClient bound to the trained surrogate.\"\"\"\n",
    "    if local_loader is None:\n",
    "        local_loader = get_surrogate_train_loader()\n",
    "    if surrogate is None:\n",
    "        surrogate = surrogate_model\n",
    "\n",
    "    client = MaliciousClient(\n",
    "        client_id=SURROGATE_CLIENT_ID,\n",
    "        local_data=local_loader,\n",
    "        device=DEVICE,\n",
    "        num_epochs=num_epochs,\n",
    "        criterion=nn.CrossEntropyLoss().to(DEVICE),\n",
    "        lr=lr if lr is not None else SURROGATE_CFG.get(\"local_lr\", 0.003),\n",
    "        attack_config=attack_config,\n",
    "    )\n",
    "    client.surrogate = surrogate.to(DEVICE)\n",
    "    client.surrogate.eval()\n",
    "    return client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa86a66",
   "metadata": {},
   "source": [
    "## 13. Attack Execution Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975e70a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_attack_fn(name: str) -> AttackFn:\n",
    "    key = name.lower()\n",
    "    if key not in ATTACK_FUNCTIONS:\n",
    "        raise KeyError(f\"Unknown attack function '{name}'. Available: {sorted(ATTACK_FUNCTIONS)}\")\n",
    "    return ATTACK_FUNCTIONS[key]\n",
    "\n",
    "\n",
    "def _attach_attack_callable(cfg: dict) -> dict:\n",
    "    cfg_copy = deepcopy(cfg)\n",
    "    attack_params = cfg_copy.setdefault(\"attack\", {})\n",
    "    attack_type = attack_params.get(\"type\", \"pgd\")\n",
    "    if \"callable\" not in attack_params:\n",
    "        attack_params[\"callable\"] = select_attack_fn(attack_type)\n",
    "    return cfg_copy\n",
    "\n",
    "\n",
    "def craft_adversarial_batch(client: MaliciousClient, inputs: torch.Tensor, labels: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    attack_params = client.attack_params\n",
    "    attack_type = attack_params.get(\"type\", \"pgd\").lower()\n",
    "    target_label = int(attack_params.get(\"target_label\", 0))\n",
    "    target_labels = torch.full_like(labels, target_label)\n",
    "    targeted = bool(attack_params.get(\"targeted\", attack_params.get(\"target_label\") is not None))\n",
    "\n",
    "    if attack_type in {\"pgd\", \"fgsm\"}:\n",
    "        attack_fn = select_attack_fn(attack_type)\n",
    "        kwargs = {\n",
    "            \"model\": client.surrogate,\n",
    "            \"criterion\": client.attack_criterion,\n",
    "            \"images\": inputs,\n",
    "            \"labels\": target_labels,\n",
    "            \"step_size\": float(attack_params.get(\"step_size\", 0.00784314)),\n",
    "        }\n",
    "        kwargs[\"targeted\"] = targeted\n",
    "        if attack_type == \"pgd\":\n",
    "            kwargs[\"eps\"] = float(attack_params.get(\"epsilon\", 0.03137255))\n",
    "            kwargs[\"iters\"] = int(attack_params.get(\"iters\", 10))\n",
    "        adv = attack_fn(**kwargs)\n",
    "    else:\n",
    "        attack_fn = select_attack_fn(\"random_noise\")\n",
    "        adv = attack_fn(inputs, step_size=float(attack_params.get(\"step_size\", 0.00784314)))\n",
    "\n",
    "    return adv, target_labels\n",
    "\n",
    "\n",
    "def evaluate_surrogate_attack(recipe_name: str, *, batch_size: int = 32) -> dict:\n",
    "    attack_cfg = _attach_attack_callable(ATTACK_RECIPES[recipe_name])\n",
    "\n",
    "    client = make_malicious_client(\n",
    "        attack_cfg,\n",
    "        num_epochs=attack_cfg.get(\"surrogate\", {}).get(\"finetune_epochs\", 0),\n",
    "    )\n",
    "    client.surrogate = surrogate_model.to(DEVICE)\n",
    "    client.surrogate.eval()\n",
    "\n",
    "    loader = get_surrogate_test_loader()\n",
    "    inputs, labels = next(iter(loader))\n",
    "    inputs = inputs[:batch_size].to(DEVICE).float()\n",
    "    labels = labels[:batch_size].to(DEVICE).long()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        clean_logits = surrogate_model(inputs)\n",
    "        clean_preds = clean_logits.argmax(dim=1)\n",
    "        clean_acc = (clean_preds == labels).float().mean().item() * 100.0\n",
    "\n",
    "    adv_inputs, adv_labels = craft_adversarial_batch(client, inputs, labels)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        adv_logits = surrogate_model(adv_inputs)\n",
    "        adv_preds = adv_logits.argmax(dim=1)\n",
    "        asr = (adv_preds == adv_labels).float().mean().item() * 100.0\n",
    "\n",
    "    return {\n",
    "        \"recipe\": recipe_name,\n",
    "        \"clean_accuracy\": clean_acc,\n",
    "        \"attack_success_rate\": asr,\n",
    "    }\n",
    "\n",
    "\n",
    "def run_attack_recipe_on_server(recipe_name: str, alg_name: str = \"FedAvg\") -> dict:\n",
    "    attack_cfg = _attach_attack_callable(ATTACK_RECIPES[recipe_name])\n",
    "    summary = run_one_algorithm(alg_name, attack_cfg=attack_cfg)\n",
    "    summary.update({\"recipe\": recipe_name, \"algorithm\": alg_name})\n",
    "    return summary\n",
    "\n",
    "\n",
    "def sweep_attacks_on_server(alg_name: str = \"FedAvg\", recipes: list[str] | None = None) -> dict:\n",
    "    recipes = recipes or list(ATTACK_RECIPES)\n",
    "    results = {}\n",
    "    for recipe in recipes:\n",
    "        if recipe == \"clean\":\n",
    "            results[recipe] = baseline_results.get(alg_name, {})\n",
    "            continue\n",
    "        results[recipe] = run_attack_recipe_on_server(recipe, alg_name=alg_name)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7656c3c",
   "metadata": {},
   "source": [
    "## 14. Surrogate Attack Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd413b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SURROGATE_ATTACK_RECIPES = [\"pgd_default\", \"fgsm_default\", \"random_noise\"]\n",
    "\n",
    "surrogate_attack_results = {\n",
    "    recipe: evaluate_surrogate_attack(recipe)\n",
    "    for recipe in SURROGATE_ATTACK_RECIPES\n",
    "}\n",
    "\n",
    "surrogate_attack_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce6d579",
   "metadata": {},
   "source": [
    "## 15. Federated Attack Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4637060",
   "metadata": {},
   "outputs": [],
   "source": [
    "FED_ATTACK_RECIPES = [\"clean\", \"pgd_default\"]\n",
    "\n",
    "federated_attack_results = sweep_attacks_on_server(\n",
    "    alg_name=\"FedAvg\",\n",
    "    recipes=FED_ATTACK_RECIPES,\n",
    ")\n",
    "\n",
    "federated_attack_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}