{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 4 Adversarial FL \u2013 Outline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Federated Baseline Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8df7305",
      "metadata": {},
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "from pathlib import Path\n",
        "\n",
        "import yaml\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from util_functions import set_seed, evaluate_fn, run_fl\n",
        "from load_data_for_clients import dist_data_per_client\n",
        "from algos import (\n",
        "    Server,\n",
        "    ScaffoldServer,\n",
        "    FedAdamServer,\n",
        "    FedAdagradServer,\n",
        "    FedYogiServer,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04c18032",
      "metadata": {},
      "source": [
        "## 2. Federated Baseline Paths & Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "370afa3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "CONFIG_PATH = Path(\"config.yaml\")\n",
        "if not CONFIG_PATH.exists():\n",
        "    raise FileNotFoundError(\"Could not locate config.yaml in the working directory\")\n",
        "\n",
        "with CONFIG_PATH.open() as f:\n",
        "    CONFIG = yaml.safe_load(f)\n",
        "\n",
        "global_config = CONFIG.get(\"global_config\", {})\n",
        "data_config = CONFIG.get(\"data_config\", {})\n",
        "model_config = CONFIG.get(\"model_config\", {})\n",
        "alg_configs = CONFIG.get(\"algorithms\", {})\n",
        "attack_defaults = CONFIG.get(\"attack\", {})\n",
        "\n",
        "set_seed(global_config.get(\"seed\", 42))\n",
        "AVAILABLE_ALGORITHMS = list(alg_configs)\n",
        "print(\"Loaded config from\", CONFIG_PATH.resolve())\n",
        "print(\"Available algorithms:\", AVAILABLE_ALGORITHMS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd69c4dd",
      "metadata": {},
      "source": [
        "## 3. Federated Baseline Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fc8a742",
      "metadata": {},
      "outputs": [],
      "source": [
        "ALGORITHM_MAP = {\n",
        "    \"FedAvg\": Server,\n",
        "    \"Scaffold\": ScaffoldServer,\n",
        "    \"FedAdam\": FedAdamServer,\n",
        "    \"FedAdagrad\": FedAdagradServer,\n",
        "    \"FedYogi\": FedYogiServer,\n",
        "}\n",
        "\n",
        "missing = sorted(set(AVAILABLE_ALGORITHMS) - set(ALGORITHM_MAP))\n",
        "if missing:\n",
        "    raise KeyError(f\"No server mapping registered for: {missing}\")\n",
        "\n",
        "\n",
        "def train_server(alg_name: str, attack_cfg: dict | None = None):\n",
        "    if alg_name not in alg_configs:\n",
        "        raise ValueError(f\"Algorithm {alg_name!r} not found in configuration.\")\n",
        "\n",
        "    alg_conf = alg_configs[alg_name]\n",
        "    fed_cfg = deepcopy(alg_conf[\"fed_config\"])\n",
        "    fed_cfg[\"algorithm\"] = alg_name\n",
        "    optim_cfg = deepcopy(alg_conf.get(\"optim_config\", {}))\n",
        "    attack_cfg = deepcopy(attack_cfg or {\"malicious_fraction\": 0.0})\n",
        "\n",
        "    return run_fl(\n",
        "        ALGORITHM_MAP[alg_name],\n",
        "        global_config,\n",
        "        data_config,\n",
        "        fed_cfg,\n",
        "        model_config,\n",
        "        optim_cfg,\n",
        "        attack_cfg,\n",
        "    )\n",
        "\n",
        "\n",
        "def summarise_server(server) -> dict:\n",
        "    loss, acc = evaluate_fn(server.data, server.x, server.criterion, server.device)\n",
        "    history = server.results if hasattr(server, \"results\") else {}\n",
        "    return {\n",
        "        \"final_loss\": float(loss),\n",
        "        \"final_accuracy\": float(acc),\n",
        "        \"history\": {\n",
        "            \"loss\": list(history.get(\"loss\", [])),\n",
        "            \"accuracy\": list(history.get(\"accuracy\", [])),\n",
        "        },\n",
        "    }\n",
        "\n",
        "\n",
        "def run_one_algorithm(alg_name: str, attack_cfg: dict | None = None) -> dict:\n",
        "    server = train_server(alg_name, attack_cfg=attack_cfg)\n",
        "    summary = summarise_server(server)\n",
        "    del server\n",
        "    torch.cuda.empty_cache()\n",
        "    return summary\n",
        "\n",
        "\n",
        "def run_all_algorithms(\n",
        "    algorithms: list[str] | None = None,\n",
        "    attack_cfg: dict | None = None,\n",
        ") -> dict:\n",
        "    algorithms = algorithms or AVAILABLE_ALGORITHMS\n",
        "    results: dict[str, dict] = {}\n",
        "    for name in algorithms:\n",
        "        results[name] = run_one_algorithm(name, attack_cfg=attack_cfg)\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bce1878b",
      "metadata": {},
      "source": [
        "## 4. Federated Baseline Runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2929a555",
      "metadata": {},
      "outputs": [],
      "source": [
        "BASELINE_ALGORITHMS = [\"FedAvg\"]  \n",
        "\n",
        "baseline_results = run_all_algorithms(BASELINE_ALGORITHMS)\n",
        "baseline_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Surrogate Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "646e69fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "from attacks import get_attack\n",
        "from malicious_client import MaliciousClient\n",
        "from model import MobileNetV2Transfer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40898ff3",
      "metadata": {},
      "source": [
        "## 6. Surrogate Paths & Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a50ffef3",
      "metadata": {},
      "outputs": [],
      "source": [
        "SURROGATE_CFG = CONFIG.get(\"surrogate\", {})\n",
        "SURROGATE_CLIENT_ID = SURROGATE_CFG.get(\"client_id\", 0)\n",
        "SURROGATE_SEED = SURROGATE_CFG.get(\"seed\", global_config.get(\"seed\", 42))\n",
        "\n",
        "def ensure_surrogate_loader():\n",
        "    loaders, _ = dist_data_per_client(\n",
        "        data_path=SURROGATE_CFG.get(\"dataset_path\", data_config.get(\"dataset_path\")),\n",
        "        dataset_name=SURROGATE_CFG.get(\"dataset_name\", data_config.get(\"dataset_name\")),\n",
        "        num_clients=SURROGATE_CFG.get(\"num_clients\", data_config.get(\"num_clients\", 50)),\n",
        "        batch_size=SURROGATE_CFG.get(\"batch_size\", data_config.get(\"batch_size\", 96)),\n",
        "        non_iid_per=SURROGATE_CFG.get(\"non_iid_per\", data_config.get(\"non_iid_per\", 0.0)),\n",
        "        device=torch.device(global_config.get(\"device\", \"cpu\")),\n",
        "    )\n",
        "    return loaders[SURROGATE_CLIENT_ID]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b5c8d9",
      "metadata": {},
      "source": [
        "## 7. Surrogate Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbf56f21",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_surrogate_model(num_classes: int = 10, pretrained: bool | None = None) -> torch.nn.Module:\n",
        "    if pretrained is None:\n",
        "        pretrained = SURROGATE_CFG.get(\"pretrained\", True)\n",
        "    model = MobileNetV2Transfer(pretrained=pretrained, num_classes=num_classes)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baa26462",
      "metadata": {},
      "source": [
        "## 8. Baseline Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d97a3c6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "surrogate_model, surrogate_summary = train_surrogate_baseline()\n",
        "\n",
        "fedavg_summary = baseline_results.get(\"FedAvg\", {})\n",
        "print(\"Federated baseline:\", fedavg_summary)\n",
        "print(\n",
        "    f\"Surrogate test metrics \u2192 loss: {surrogate_summary['test_loss']:.4f}, accuracy: {surrogate_summary['test_accuracy']:.2f}%\"\n",
        ")\n",
        "\n",
        "surrogate_summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd2416be",
      "metadata": {},
      "source": [
        "## 9. Attack Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6e1da11",
      "metadata": {},
      "outputs": [],
      "source": [
        "from attacks import get_attack, pgd_attack, fgsm_attack, random_noise_attack\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Attack Paths & Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ATTACK_RAW = attack_defaults\n",
        "ATTACK_SEED = ATTACK_RAW.get(\"seed\", global_config.get(\"seed\", 42))\n",
        "BASE_MALICIOUS_FRACTION = ATTACK_RAW.get(\"malicious_fraction\", 0.0)\n",
        "\n",
        "\n",
        "def _extract_attack_params(overrides: dict | None = None) -> dict:\n",
        "    params = {\n",
        "        \"type\": ATTACK_RAW.get(\"type\", \"pgd\"),\n",
        "        \"poison_rate\": ATTACK_RAW.get(\"poison_rate\", 0.0),\n",
        "        \"target_label\": ATTACK_RAW.get(\"target_label\", 0),\n",
        "        \"epsilon\": ATTACK_RAW.get(\"epsilon\", 0.03137255),\n",
        "        \"step_size\": ATTACK_RAW.get(\"step_size\", 0.00784314),\n",
        "        \"iters\": ATTACK_RAW.get(\"iters\", 10),\n",
        "        \"criterion\": ATTACK_RAW.get(\"criterion\", \"torch.nn.CrossEntropyLoss\"),\n",
        "    }\n",
        "    schedule = ATTACK_RAW.get(\"poison_rate_schedule\")\n",
        "    if schedule:\n",
        "        params[\"poison_rate_schedule\"] = schedule\n",
        "    if overrides:\n",
        "        params.update(overrides)\n",
        "    return params\n",
        "\n",
        "\n",
        "def _extract_surrogate_params(overrides: dict | None = None) -> dict:\n",
        "    params = {\n",
        "        \"pretrained\": ATTACK_RAW.get(\"surrogate_pretrained\", True),\n",
        "        \"finetune_epochs\": ATTACK_RAW.get(\"surrogate_finetune_epochs\", 0),\n",
        "        \"lr\": ATTACK_RAW.get(\"surrogate_lr\", 1e-3),\n",
        "        \"batch_size\": ATTACK_RAW.get(\"surrogate_batch_size\", SURROGATE_CFG.get(\"batch_size\", data_config.get(\"batch_size\", 96))),\n",
        "        \"client_id\": SURROGATE_CFG.get(\"client_id\", 0),\n",
        "        \"num_classes\": SURROGATE_CFG.get(\"num_classes\", model_config.get(\"kwargs\", {}).get(\"num_classes\", 10)),\n",
        "        \"criterion\": ATTACK_RAW.get(\"criterion\", \"torch.nn.CrossEntropyLoss\"),\n",
        "    }\n",
        "    if overrides:\n",
        "        params.update(overrides)\n",
        "    return params\n",
        "\n",
        "\n",
        "def build_attack_config(*, attack_overrides: dict | None = None, surrogate_overrides: dict | None = None, malicious_fraction: float | None = None, seed: int | None = None) -> dict:\n",
        "    cfg = {\n",
        "        \"seed\": seed if seed is not None else ATTACK_SEED,\n",
        "        \"malicious_fraction\": BASE_MALICIOUS_FRACTION if malicious_fraction is None else malicious_fraction,\n",
        "        \"attack\": _extract_attack_params(attack_overrides),\n",
        "        \"surrogate\": _extract_surrogate_params(surrogate_overrides),\n",
        "    }\n",
        "    for key in (\"start_round\",):\n",
        "        if key in ATTACK_RAW:\n",
        "            cfg[key] = ATTACK_RAW[key]\n",
        "    return cfg\n",
        "\n",
        "\n",
        "ATTACK_RECIPES = {\n",
        "    \"clean\": build_attack_config(malicious_fraction=0.0, attack_overrides={\"poison_rate\": 0.0}),\n",
        "    \"pgd_default\": build_attack_config(),\n",
        "    \"fgsm_default\": build_attack_config(attack_overrides={\"type\": \"fgsm\", \"iters\": 1}),\n",
        "    \"random_noise\": build_attack_config(attack_overrides={\"type\": \"random_noise\"}),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Attack Implementations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Callable, Dict\n",
        "\n",
        "AttackFn = Callable[..., torch.Tensor]\n",
        "\n",
        "\n",
        "def pgd_attack(\n",
        "    model: torch.nn.Module,\n",
        "    criterion: torch.nn.Module,\n",
        "    images: torch.Tensor,\n",
        "    labels: torch.Tensor,\n",
        "    eps: float,\n",
        "    step_size: float,\n",
        "    iters: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Projected Gradient Descent with an L-infinity constraint.\"\"\"\n",
        "    ori = images.clone().detach()\n",
        "    adv = ori.clone().detach()\n",
        "\n",
        "    for _ in range(iters):\n",
        "        adv.requires_grad_(True)\n",
        "        outputs = model(adv)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        model.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "\n",
        "        adv = adv + step_size * adv.grad.sign()\n",
        "        eta = torch.clamp(adv - ori, min=-eps, max=eps)\n",
        "        adv = torch.clamp(ori + eta, 0, 1).detach()\n",
        "\n",
        "    return adv\n",
        "\n",
        "\n",
        "def fgsm_attack(\n",
        "    model: torch.nn.Module,\n",
        "    criterion: torch.nn.Module,\n",
        "    images: torch.Tensor,\n",
        "    labels: torch.Tensor,\n",
        "    step_size: float,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Single gradient-sign step.\"\"\"\n",
        "    adv = images.clone().detach().requires_grad_(True)\n",
        "    loss = criterion(model(adv), labels)\n",
        "\n",
        "    model.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "\n",
        "    adv = adv + step_size * adv.grad.sign()\n",
        "    return torch.clamp(adv, 0, 1).detach()\n",
        "\n",
        "\n",
        "def random_noise_attack(images: torch.Tensor, step_size: float) -> torch.Tensor:\n",
        "    \"\"\"Add random signed noise to the batch and clamp to valid bounds.\"\"\"\n",
        "    perturb = torch.randn_like(images).sign()\n",
        "    adv = images + step_size * perturb\n",
        "    return torch.clamp(adv, 0, 1).detach()\n",
        "\n",
        "\n",
        "ATTACK_FUNCTIONS: Dict[str, AttackFn] = {\n",
        "    \"pgd\": pgd_attack,\n",
        "    \"fgsm\": fgsm_attack,\n",
        "    \"random\": random_noise_attack,\n",
        "    \"random_noise\": random_noise_attack,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Malicious Client Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_malicious_client(\n",
        "    attack_config: dict,\n",
        "    *,\n",
        "    local_loader=None,\n",
        "    surrogate=None,\n",
        "    num_epochs: int = 0,\n",
        "    lr: float | None = None,\n",
        "):\n",
        "    \"\"\"Helper to instantiate a MaliciousClient bound to the trained surrogate.\"\"\"\n",
        "    if local_loader is None:\n",
        "        local_loader = get_surrogate_train_loader()\n",
        "    if surrogate is None:\n",
        "        surrogate = surrogate_model\n",
        "\n",
        "    client = MaliciousClient(\n",
        "        client_id=SURROGATE_CLIENT_ID,\n",
        "        local_data=local_loader,\n",
        "        device=DEVICE,\n",
        "        num_epochs=num_epochs,\n",
        "        criterion=nn.CrossEntropyLoss().to(DEVICE),\n",
        "        lr=lr if lr is not None else SURROGATE_CFG.get(\"local_lr\", 0.003),\n",
        "        attack_config=attack_config,\n",
        "    )\n",
        "    client.surrogate = surrogate.to(DEVICE)\n",
        "    client.surrogate.eval()\n",
        "    return client\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Attack Execution Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def select_attack_fn(name: str) -> AttackFn:\n",
        "    key = name.lower()\n",
        "    if key not in ATTACK_FUNCTIONS:\n",
        "        raise KeyError(f\"Unknown attack function '{name}'. Available: {sorted(ATTACK_FUNCTIONS)}\")\n",
        "    return ATTACK_FUNCTIONS[key]\n",
        "\n",
        "\n",
        "def craft_adversarial_batch(client: MaliciousClient, inputs: torch.Tensor, labels: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "    attack_params = client.attack_params\n",
        "    attack_type = attack_params.get(\"type\", \"pgd\").lower()\n",
        "    target_label = int(attack_params.get(\"target_label\", 0))\n",
        "    target_labels = torch.full_like(labels, target_label)\n",
        "\n",
        "    if attack_type in {\"pgd\", \"fgsm\"}:\n",
        "        attack_fn = select_attack_fn(attack_type)\n",
        "        kwargs = {\n",
        "            \"model\": client.surrogate,\n",
        "            \"criterion\": client.attack_criterion,\n",
        "            \"images\": inputs,\n",
        "            \"labels\": target_labels,\n",
        "            \"step_size\": float(attack_params.get(\"step_size\", 0.00784314)),\n",
        "        }\n",
        "        if attack_type == \"pgd\":\n",
        "            kwargs[\"eps\"] = float(attack_params.get(\"epsilon\", 0.03137255))\n",
        "            kwargs[\"iters\"] = int(attack_params.get(\"iters\", 10))\n",
        "        adv = attack_fn(**kwargs)\n",
        "    else:\n",
        "        attack_fn = select_attack_fn(\"random_noise\")\n",
        "        adv = attack_fn(inputs, step_size=float(attack_params.get(\"step_size\", 0.00784314)))\n",
        "\n",
        "    return adv, target_labels\n",
        "\n",
        "\n",
        "def evaluate_surrogate_attack(recipe_name: str, *, batch_size: int = 32) -> dict:\n",
        "    attack_cfg = deepcopy(ATTACK_RECIPES[recipe_name])\n",
        "\n",
        "    client = make_malicious_client(\n",
        "        attack_cfg,\n",
        "        num_epochs=attack_cfg.get(\"surrogate\", {}).get(\"finetune_epochs\", 0),\n",
        "    )\n",
        "    client.surrogate = surrogate_model.to(DEVICE)\n",
        "    client.surrogate.eval()\n",
        "\n",
        "    loader = get_surrogate_test_loader()\n",
        "    inputs, labels = next(iter(loader))\n",
        "    inputs = inputs[:batch_size].to(DEVICE).float()\n",
        "    labels = labels[:batch_size].to(DEVICE).long()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        clean_logits = surrogate_model(inputs)\n",
        "        clean_preds = clean_logits.argmax(dim=1)\n",
        "        clean_acc = (clean_preds == labels).float().mean().item() * 100.0\n",
        "\n",
        "    adv_inputs, adv_labels = craft_adversarial_batch(client, inputs, labels)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        adv_logits = surrogate_model(adv_inputs)\n",
        "        adv_preds = adv_logits.argmax(dim=1)\n",
        "        asr = (adv_preds == adv_labels).float().mean().item() * 100.0\n",
        "\n",
        "    return {\n",
        "        \"recipe\": recipe_name,\n",
        "        \"clean_accuracy\": clean_acc,\n",
        "        \"attack_success_rate\": asr,\n",
        "    }\n",
        "\n",
        "\n",
        "def run_attack_recipe_on_server(recipe_name: str, alg_name: str = \"FedAvg\") -> dict:\n",
        "    attack_cfg = deepcopy(ATTACK_RECIPES[recipe_name])\n",
        "    summary = run_one_algorithm(alg_name, attack_cfg=attack_cfg)\n",
        "    summary.update({\"recipe\": recipe_name, \"algorithm\": alg_name})\n",
        "    return summary\n",
        "\n",
        "\n",
        "def sweep_attacks_on_server(alg_name: str = \"FedAvg\", recipes: list[str] | None = None) -> dict:\n",
        "    recipes = recipes or list(ATTACK_RECIPES)\n",
        "    results = {}\n",
        "    for recipe in recipes:\n",
        "        if recipe == \"clean\":\n",
        "            results[recipe] = baseline_results.get(alg_name, {})\n",
        "            continue\n",
        "        results[recipe] = run_attack_recipe_on_server(recipe, alg_name=alg_name)\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Surrogate Attack Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SURROGATE_ATTACK_RECIPES = [\"pgd_default\", \"fgsm_default\", \"random_noise\"]\n",
        "\n",
        "surrogate_attack_results = {\n",
        "    recipe: evaluate_surrogate_attack(recipe)\n",
        "    for recipe in SURROGATE_ATTACK_RECIPES\n",
        "}\n",
        "\n",
        "surrogate_attack_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Federated Attack Sweeps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FED_ATTACK_RECIPES = [\"clean\", \"pgd_default\"]\n",
        "\n",
        "federated_attack_results = sweep_attacks_on_server(\n",
        "    alg_name=\"FedAvg\",\n",
        "    recipes=FED_ATTACK_RECIPES,\n",
        ")\n",
        "\n",
        "federated_attack_results\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}