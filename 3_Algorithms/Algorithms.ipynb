{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 â€” Federated Optimization Algorithms (FedAvg, FedOpt, SCAFFOLD)\n",
    "\n",
    "This notebook compares multiple **federated server update rules** under the same training setup.\n",
    "\n",
    "We will run:\n",
    "- **FedAvg** (baseline)\n",
    "- **FedAdagrad**, **FedAdam**, **FedYogi** (FedOpt family: server-side adaptive optimization)\n",
    "- **SCAFFOLD** (control variates to reduce client drift)\n",
    "\n",
    "**Outputs:** comparison plots (accuracy/loss vs rounds) and a small summary of final metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from federated_core import BaseClient, BaseServer\n",
    "from util_functions import set_seed, evaluate_fn\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load configuration and data\n",
    "\n",
    "Read the federated config, apply the global seed, and prepare shared data/model settings for every algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = Path('config.yaml')\n",
    "if not CONFIG_PATH.exists():\n",
    "    raise FileNotFoundError('Could not locate config.yaml for Section 3')\n",
    "\n",
    "config = yaml.safe_load(CONFIG_PATH.read_text())\n",
    "global_config = config['global_config']\n",
    "data_config = config['data_config']\n",
    "model_config = config['model_config']\n",
    "alg_configs = config['algorithms']\n",
    "\n",
    "DEVICE = torch.device(global_config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "set_seed(global_config.get('seed', 42))\n",
    "\n",
    "ARTIFACT_DIR = Path('artifacts')\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm definitions\n",
    "\n",
    "Define the algorithm-specific server subclasses (and any specialised clients) that override the base aggregation behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class FedAvgServer(BaseServer):\n    \"\"\"Vanilla FedAvg uses the base aggregation (simple average).\"\"\"\n    pass\n\nclass FedAdamServer(BaseServer):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.beta1 = self.optim_config.get('beta1', 0.9)\n        self.beta2 = self.optim_config.get('beta2', 0.99)\n        self.epsilon = self.optim_config.get('epsilon', 1e-6)\n        param_state = self._parameter_state_dict()\n        self.m = {name: torch.zeros_like(tensor) for name, tensor in param_state.items()}\n        self.v = {name: torch.zeros_like(tensor) for name, tensor in param_state.items()}\n    def aggregate(self, local_states):\n        if not local_states:\n            return\n        global_params = self._parameter_state_dict()\n        delta_params = []\n        for state in local_states:\n            delta_params.append({name: state[name] - global_params[name] for name in global_params})\n        mean_delta = self._average_state_dicts(delta_params)\n        updated = {}\n        for name, param in global_params.items():\n            delta = mean_delta[name]\n            self.m[name] = self.beta1 * self.m[name] + (1 - self.beta1) * delta\n            self.v[name] = self.beta2 * self.v[name] + (1 - self.beta2) * torch.square(delta)\n            # FIX: Add safety clamping to prevent numerical issues\n            self.v[name] = torch.clamp(self.v[name], min=1e-10)\n            updated[name] = param + self.global_lr * self.m[name] / (torch.sqrt(self.v[name]) + self.epsilon)\n        full_state = self._global_state_cpu()\n        for name in updated:\n            full_state[name] = updated[name]\n        self.global_model.load_state_dict(full_state)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class FedAdagradServer(BaseServer):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.epsilon = self.optim_config.get('epsilon', 1e-6)\n        param_state = self._parameter_state_dict()\n        # FIX: Initialize with zeros (standard Adagrad)\n        self.s = {name: torch.zeros_like(tensor) for name, tensor in param_state.items()}\n    def aggregate(self, local_states):\n        if not local_states:\n            return\n        global_params = self._parameter_state_dict()\n        delta_params = []\n        for state in local_states:\n            delta_params.append({name: state[name] - global_params[name] for name in global_params})\n        mean_delta = self._average_state_dicts(delta_params)\n        updated = {}\n        for name, param in global_params.items():\n            delta = mean_delta[name]\n            self.s[name] = self.s[name] + torch.square(delta)\n            # FIX: Remove double damping - use only epsilon\n            updated[name] = param + self.global_lr * delta / (torch.sqrt(self.s[name]) + self.epsilon)\n        full_state = self._global_state_cpu()\n        for name in updated:\n            full_state[name] = updated[name]\n        self.global_model.load_state_dict(full_state)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class FedYogiServer(BaseServer):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.beta1 = self.optim_config.get('beta1', 0.9)\n        self.beta2 = self.optim_config.get('beta2', 0.99)\n        self.epsilon = self.optim_config.get('epsilon', 1e-6)\n        param_state = self._parameter_state_dict()\n        self.m = {name: torch.zeros_like(tensor) for name, tensor in param_state.items()}\n        self.v = {name: torch.zeros_like(tensor) for name, tensor in param_state.items()}\n        self.timestep = 1\n    def aggregate(self, local_states):\n        if not local_states:\n            return\n        global_params = self._parameter_state_dict()\n        delta_params = []\n        for state in local_states:\n            delta_params.append({name: state[name] - global_params[name] for name in global_params})\n        mean_delta = self._average_state_dicts(delta_params)\n        updated = {}\n        for name, param in global_params.items():\n            delta = mean_delta[name]\n            self.m[name] = self.beta1 * self.m[name] + (1 - self.beta1) * delta\n            # FIX: Clamp v to prevent negative values that cause sqrt to fail\n            self.v[name] = torch.clamp(\n                self.v[name] - (1 - self.beta2) * torch.sign(self.v[name] - torch.square(delta)) * torch.square(delta),\n                min=self.epsilon\n            )\n            updated[name] = param + self.global_lr * self.m[name] / (torch.sqrt(self.v[name]) + self.epsilon)\n        self.timestep += 1\n        full_state = self._global_state_cpu()\n        for name in updated:\n            full_state[name] = updated[name]\n        self.global_model.load_state_dict(full_state)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaffoldClient(BaseClient):\n",
    "    def __init__(self, *args, control_init: dict[str, torch.Tensor] | None = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.client_c = control_init or {}\n",
    "        self.server_c: dict[str, torch.Tensor] | None = None\n",
    "    def set_server_controls(self, server_c: dict[str, torch.Tensor]):\n",
    "        self.server_c = {k: v.clone() for k, v in server_c.items()}\n",
    "    def train_with_controls(self, global_model: torch.nn.Module):\n",
    "        if self.server_c is None:\n",
    "            raise RuntimeError('Server controls must be provided before training.')\n",
    "        local_model = deepcopy(global_model).to(self.device)\n",
    "        local_model.train()\n",
    "        param_names = [name for name, _ in local_model.named_parameters()]\n",
    "        params = [param for _, param in local_model.named_parameters()]\n",
    "        server_controls = [self.server_c[name].to(self.device) for name in param_names]\n",
    "        client_controls = [self.client_c[name].to(self.device) for name in param_names]\n",
    "        for _ in range(self.num_epochs):\n",
    "            for inputs, labels in self.data:\n",
    "                inputs = inputs.float().to(self.device)\n",
    "                labels = labels.long().to(self.device)\n",
    "                outputs = local_model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                grads = torch.autograd.grad(loss, params)\n",
    "                for param, grad, s_c, c_c in zip(params, grads, server_controls, client_controls):\n",
    "                    param.data -= self.lr * (grad + s_c - c_c)\n",
    "        local_params = {name: param.detach().cpu() for name, param in local_model.named_parameters()}\n",
    "        global_params = {name: param.detach().cpu() for name, param in global_model.named_parameters()}\n",
    "        delta_y = {name: local_params[name] - global_params[name] for name in global_params}\n",
    "        steps_per_epoch = math.ceil(len(self.data.dataset) / self.data.batch_size) if self.data.batch_size else 0\n",
    "        total_steps = max(steps_per_epoch * self.num_epochs, 1)\n",
    "        scale = total_steps * self.lr\n",
    "        new_client_c = {}\n",
    "        delta_c = {}\n",
    "        for name in global_params:\n",
    "            new_client_c[name] = self.client_c[name] - self.server_c[name] - delta_y[name] / scale\n",
    "            delta_c[name] = new_client_c[name] - self.client_c[name]\n",
    "        self.client_c = new_client_c\n",
    "        return local_params, delta_y, delta_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class ScaffoldServer(BaseServer):\n    def __init__(self, *args, **kwargs):\n        self.c_init = (kwargs.get('optim_config') or {}).get('c_init', 0.0)\n        super().__init__(*args, client_cls=BaseClient, **kwargs)\n        self.server_c = self._zeros_like_parameters()\n        # Replace base clients with Scaffold-aware clients\n        self.clients = []\n    def setup(self) -> None:\n        super().setup()\n        control_init = {name: torch.full_like(param, self.c_init) for name, param in self._parameter_state_dict().items()}\n        self.clients = [\n            ScaffoldClient(\n                client_id=client.id,\n                local_data=client.data,\n                device=client.device,\n                num_epochs=client.num_epochs,\n                lr=client.lr,\n                criterion=client.criterion,\n                control_init=deepcopy(control_init),\n            )\n            for client in self.clients\n        ]\n    def collect_client_updates(self, client_ids):\n        updates = []\n        for idx in client_ids:\n            client: ScaffoldClient = self.clients[idx]\n            client.set_server_controls(self.server_c)\n            local_params, delta_y, delta_c = client.train_with_controls(self.global_model)\n            updates.append((idx, local_params, delta_y, delta_c))\n        return updates\n    def aggregate(self, updates):\n        if not updates:\n            return\n        _, _, delta_y_list, delta_c_list = zip(*updates)\n        mean_delta = self._average_state_dicts(delta_y_list)\n        global_params = self._parameter_state_dict()\n        # Update global model\n        for name in global_params:\n            global_params[name] = global_params[name] + self.global_lr * mean_delta[name]\n        full_state = self._global_state_cpu()\n        for name in global_params:\n            full_state[name] = global_params[name]\n        self.global_model.load_state_dict(full_state)\n        # FIX: Update control variates by averaging delta_c over participating clients\n        mean_delta_c = self._average_state_dicts(delta_c_list)\n        for name in self.server_c:\n            self.server_c[name] = self.server_c[name] + mean_delta_c[name]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM_MAP = {\n",
    "    'FedAvg': FedAvgServer,\n",
    "    'Scaffold': ScaffoldServer,\n",
    "    'FedAdam': FedAdamServer,\n",
    "    'FedAdagrad': FedAdagradServer,\n",
    "    'FedYogi': FedYogiServer,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper to run an algorithm\n",
    "\n",
    "Instantiate the server, set up clients, train for the configured rounds, and return final metrics plus history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm(name: str):\n",
    "    alg_conf = deepcopy(alg_configs[name])\n",
    "    fed_cfg = deepcopy(alg_conf['fed_config'])\n",
    "    server_cls = ALGORITHM_MAP[name]\n",
    "    server = server_cls(\n",
    "        model_config=model_config,\n",
    "        global_config=global_config,\n",
    "        data_config=data_config,\n",
    "        fed_config=fed_cfg,\n",
    "        optim_config=alg_conf.get('optim_config', {}),\n",
    "    )\n",
    "    server.setup()\n",
    "    server.train()\n",
    "    loss, acc = evaluate_fn(server.test_loader, server.global_model, server.criterion, server.device)\n",
    "    history = server.results\n",
    "    return {'final_loss': loss, 'final_accuracy': acc, 'history': history}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute all algorithms\n",
    "\n",
    "Run each configured optimiser once and capture its training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this list to run one algorithm at a time if GPU memory is limited.\n",
    "ALGORITHMS_TO_RUN = list(alg_configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name in ALGORITHMS_TO_RUN:\n",
    "    print(f'Running {name} ...')\n",
    "    results[name] = run_algorithm(name)\n",
    "    torch.cuda.empty_cache()\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy over rounds\n",
    "\n",
    "Visualise how each optimiser converges on the global test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histories(results):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for name, summary in results.items():\n",
    "        acc = summary['history'].get('accuracy')\n",
    "        if acc:\n",
    "            plt.plot(acc, label=name)\n",
    "    plt.xlabel('Communication round')\n",
    "    plt.ylabel('Test accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.title('Algorithm convergence comparison')\n",
    "plot_histories(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final metrics\n",
    "\n",
    "Tabulate final loss and accuracy to compare end-of-training performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame({name: {'final_loss': res['final_loss'], 'final_accuracy': res['final_accuracy']} for name, res in results.items()}).T\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist artefacts\n",
    "\n",
    "Save the convergence history and summary table so instructors can share reference results without rerunning the lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_export = {name: res['history'] for name, res in results.items()}\n",
    "summary_path = ARTIFACT_DIR / 'module3_summary.csv'\n",
    "history_path = ARTIFACT_DIR / 'module3_histories.json'\n",
    "summary_df.to_csv(summary_path, float_format='%.4f')\n",
    "with history_path.open('w') as f:\n",
    "    json.dump(history_export, f, indent=2)\n",
    "print(f'Saved summary to {summary_path.resolve()}')\n",
    "print(f'Saved histories to {history_path.resolve()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation checks\n",
    "\n",
    "Ensure each algorithm logged the expected number of rounds and produced non-trivial accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_histories(results, algorithm_config):\n",
    "    issues = []\n",
    "    for name, summary in results.items():\n",
    "        expected = algorithm_config[name]['fed_config']['num_rounds']\n",
    "        actual = len(summary['history'].get('accuracy', []))\n",
    "        if actual < expected:\n",
    "            issues.append(f\"{name}: expected {expected} rounds, saw {actual}\")\n",
    "        if summary['final_accuracy'] <= 0:\n",
    "            issues.append(f\"{name}: non-positive final accuracy {summary['final_accuracy']}\")\n",
    "    if issues:\n",
    "        raise ValueError('History validation failed:\n",
    "' + '\n",
    "'.join(issues))\n",
    "    print('Validation passed for', ', '.join(sorted(results)))\n",
    "\n",
    "validate_histories(results, alg_configs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick takeaway\n",
    "\n",
    "Highlight the top-performing optimiser based on the final accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alg = summary_df['final_accuracy'].idxmax()\n",
    "best_acc = summary_df.loc[best_alg, 'final_accuracy']\n",
    "worst_acc = summary_df['final_accuracy'].min()\n",
    "print(f'Best performer: {best_alg} with {best_acc:.2f}% accuracy.')\n",
    "print(f'Accuracy gap vs. slowest optimiser: {best_acc - worst_acc:.2f} percentage points.')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOcdzrhV770ujU8gpuX7OUB",
   "mount_file_id": "1HxSoY3NuOuFA-bfIbilNVktg15M4SRUn",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}