{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYjvZ3vMyaTZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-IID Data in Federated Learning\n",
    "\n",
    "In real federated learning, client data is rarely **IID** (independent & identically distributed). Clients usually reflect different users, devices, regions, or institutions, so their local label distributions differ.\n",
    "\n",
    "In this notebook we simulate **label distribution skew** on MNIST and observe how it affects FedAvg training.\n",
    "\n",
    "## IID vs Non-IID (what we mean here)\n",
    "- **IID split:** each client receives an unbiased random subset of the global dataset.\n",
    "- **Non-IID split (label skew):** clients receive different class mixtures (some clients see mostly a few digits).\n",
    "\n",
    "## Dirichlet partitioning (how we create skew)\n",
    "We use a Dirichlet-based split to generate per-class allocation proportions across clients. The **concentration parameter** controls skew:\n",
    "- smaller concentration → more skew (clients specialize),\n",
    "- larger concentration → more uniform (closer to IID).\n",
    "\n",
    "### Notebook knob: `non_iid_per`\n",
    "This notebook uses a single knob `non_iid_per ∈ [0, 1]` and converts it to a Dirichlet concentration `alpha`:\n",
    "- `non_iid_per = 0` → close to IID (`alpha ≈ 1`)\n",
    "- `non_iid_per → 1` → strong skew (`alpha` near `0.01`)\n",
    "\n",
    "**What to watch:** as skew increases, FedAvg typically converges slower and/or reaches lower global accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSc48na9xwU1"
   },
   "outputs": [],
   "source": [
    "import os, math, random, logging\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool  = nn.MaxPool2d(2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(64 * 14 * 14, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist(root=\"./data\"):\n",
    "\n",
    "    _ = datasets.MNIST(root=root, train=True,  download=True)\n",
    "    _ = datasets.MNIST(root=root, train=False, download=True)\n",
    "    print(f\"MNIST downloaded to: {os.path.abspath(root)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_transforms():\n",
    "\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "def load_mnist_with_transforms(root=\"./data\", transform=None):\n",
    "\n",
    "    if transform is None:\n",
    "        transform = mnist_transforms()\n",
    "    train_ds = datasets.MNIST(root=root, train=True,  download=False, transform=transform)\n",
    "    test_ds  = datasets.MNIST(root=root, train=False, download=False, transform=transform)\n",
    "    return train_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _iid_indices(n_items, num_clients, seed=42):\n",
    "    # print(\"iid\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(n_items)\n",
    "    rng.shuffle(idx)\n",
    "    splits = np.array_split(idx, num_clients)\n",
    "    return [np.array(s, dtype=int) for s in splits]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WEK1bNezDa5Y"
   },
   "outputs": [],
   "source": [
    "\n",
    "def _dirichlet_label_skew_indices(targets, num_clients, alpha=0.5, seed=42):\n",
    "\n",
    "    # print(\"skew\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "    targets = np.asarray(targets)\n",
    "    classes = np.unique(targets)\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "\n",
    "    for c in classes:\n",
    "        c_idx = np.where(targets == c)[0]\n",
    "        rng.shuffle(c_idx)\n",
    "\n",
    "        props = rng.dirichlet([alpha] * num_clients)\n",
    "\n",
    "        counts = (len(c_idx) * props).astype(int)\n",
    "\n",
    "        while counts.sum() < len(c_idx):\n",
    "            counts[np.argmax(props)] += 1\n",
    "\n",
    "        start = 0\n",
    "        for i, cnt in enumerate(counts):\n",
    "            if cnt > 0:\n",
    "                client_indices[i].extend(c_idx[start:start+cnt])\n",
    "                start += cnt\n",
    "\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        client_indices[i] = np.array(client_indices[i], dtype=int)\n",
    "        rng.shuffle(client_indices[i])\n",
    "    return client_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U74oPOJuAq9W"
   },
   "source": [
    "# Load client data (DataLoaders per client)\n",
    "\n",
    "We convert the global training dataset into **one DataLoader per client**:\n",
    "\n",
    "- `client_loaders[i]` yields batches from *client i’s private training set*.\n",
    "- `test_loader` is a shared test DataLoader used only for evaluation of the global model.\n",
    "\n",
    "## Split logic\n",
    "- If `non_iid_per` is ~0, we create an IID random split of indices across clients.\n",
    "- Otherwise, we build a **Dirichlet label-skew split** so each client gets a different label mixture.\n",
    "\n",
    "This is the key step that turns a centralized dataset into a federated setting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3JX-JIgAoS5"
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_client_loaders(\n",
    "    train_ds,\n",
    "    test_ds,\n",
    "    num_clients=10,\n",
    "    batch_size=64,\n",
    "    non_iid_per=0.0,\n",
    "    seed=42,\n",
    "    return_indices=False,\n",
    "):\n",
    "\n",
    "    if non_iid_per <= 1e-8:\n",
    "        client_idxs = _iid_indices(len(train_ds), num_clients, seed=seed)\n",
    "    else:\n",
    "        alpha = max(0.01, 1.0 - 0.99 * non_iid_per)\n",
    "        targets = train_ds.targets if hasattr(train_ds, \"targets\") else train_ds.labels\n",
    "        client_idxs = _dirichlet_label_skew_indices(targets, num_clients, alpha=alpha, seed=seed)\n",
    "\n",
    "    local_loaders = [\n",
    "        DataLoader(Subset(train_ds, idxs), batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "        for idxs in client_idxs\n",
    "    ]\n",
    "    test_loader = DataLoader(test_ds, batch_size=512, shuffle=False, drop_last=False)\n",
    "\n",
    "    return (local_loaders, test_loader, client_idxs) if return_indices else (local_loaders, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuTz4veEs5gx"
   },
   "source": [
    "# Client: local training on private data\n",
    "\n",
    "A `Client` simulates one participant in FL. Each client holds:\n",
    "- `data`: its own DataLoader (private samples)\n",
    "- `x`: a reference to the **current global model** (received each round)\n",
    "- `y`: the **local model copy** trained on this client (produced each round)\n",
    "\n",
    "## Local update idea\n",
    "In each round:\n",
    "1. The server assigns `client.x = global_model`\n",
    "2. The client deep-copies `x → y` (so it can train locally)\n",
    "3. The client trains `y` for `num_epochs` on its private batches\n",
    "4. The trained `y` is sent back to the server for aggregation\n",
    "\n",
    "This notebook uses a simple manual SGD-style update using gradients computed from the loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdWuIMZhxwU3"
   },
   "outputs": [],
   "source": [
    "class Client():\n",
    "    def __init__(self, client_id, local_data, device, num_epochs, criterion, lr):\n",
    "        self.id = client_id\n",
    "        self.data = local_data\n",
    "        self.device = device if isinstance(device, torch.device) else torch.device(device)\n",
    "        self.num_epochs = num_epochs\n",
    "        self.lr = lr\n",
    "        self.criterion = criterion\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    def client_update(self):\n",
    "        self.y = deepcopy(self.x)\n",
    "        self.y.to(self.device)\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for inputs, labels in self.data:\n",
    "                inputs = inputs.float().to(self.device)\n",
    "                labels = labels.long().to(self.device)\n",
    "\n",
    "                output = self.y(inputs)\n",
    "                loss = self.criterion(output, labels)\n",
    "                grads = torch.autograd.grad(loss, self.y.parameters())\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for param, grad in zip(self.y.parameters(), grads):\n",
    "                        param.data = param.data - self.lr * grad.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTHAdDkhA_zF"
   },
   "source": [
    "# Evaluate function (global model performance)\n",
    "\n",
    "After aggregation, we evaluate the **global model** on a shared test set.\n",
    "\n",
    "What this function does:\n",
    "- sets the model to `eval()` mode,\n",
    "- disables gradient computation (`torch.no_grad()`),\n",
    "- computes average loss across all test samples,\n",
    "- computes accuracy (%) across all test samples.\n",
    "\n",
    "This gives us a consistent metric to compare across rounds and across different non-IID settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e_zmWJo9xwU3"
   },
   "outputs": [],
   "source": [
    "def evaluate_fn(test_loader, model, criterion, device):\n",
    "    # print(\"eval\")\n",
    "    model.eval()\n",
    "    n, total_loss, correct = 0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device, dtype=torch.float)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            pred = logits.argmax(dim=1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            n += x.size(0)\n",
    "    return (total_loss / max(1, n)), (100.0 * correct / max(1, n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNjy8PjuBUMP"
   },
   "source": [
    "# Client Sampling (partial participation)\n",
    "\n",
    "Real FL systems rarely have all clients available every round.\n",
    "To simulate this, we sample only a fraction of clients each round:\n",
    "\n",
    "- `fraction = 0.2` means ~20% of clients participate per round\n",
    "- Sampling changes training dynamics and adds variance to the updates\n",
    "\n",
    "This is why we track performance across many rounds rather than judging a single round.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "M9ejG82eBOg0"
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample_clients(num_clients, fraction, rng):\n",
    "    k = max(1, int(math.ceil(fraction * num_clients)))\n",
    "    return sorted(rng.choice(np.arange(num_clients), size=k, replace=False).tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-GWDch3Bb1D"
   },
   "source": [
    "# Federated Averaging (FedAvg)\n",
    "\n",
    "FedAvg aggregates the client-trained models into a new global model by averaging parameters.\n",
    "\n",
    "In this implementation:\n",
    "- we average each parameter tensor across the participating clients\n",
    "- each participating client contributes equally\n",
    "\n",
    "Note: Many FL implementations use a **weighted average** (by each client’s dataset size). This notebook uses the simplest unweighted baseline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Lvhr183bBQfF"
   },
   "outputs": [],
   "source": [
    "\n",
    "def fedavg_aggregate(global_model, client_models, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # init accumulators\n",
    "        acc = [torch.zeros_like(p, device=device) for p in global_model.parameters()]\n",
    "        for cm in client_models:\n",
    "            for a, p in zip(acc, cm.parameters()):\n",
    "                a.add_(p.to(device))\n",
    "        for gp, a in zip(global_model.parameters(), acc):\n",
    "            gp.copy_(a / len(client_models))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ez9vTaExBrpF"
   },
   "source": [
    "# Training (FedAvg rounds)\n",
    "\n",
    "`train_fedavg(...)` runs the full FL process:\n",
    "\n",
    "Per round:\n",
    "1. **Sample clients** based on `fraction`\n",
    "2. **Broadcast** the current global model to selected clients (`client.x = global_model`)\n",
    "3. **Local training** on each selected client (`client.client_update()`)\n",
    "4. **Aggregate** client models into the global model (FedAvg)\n",
    "5. **Evaluate** the global model on the test set\n",
    "6. **Log** metrics into `history` for plotting\n",
    "\n",
    "Output:\n",
    "- `global_model`: trained model after all rounds\n",
    "- `history`: per-round loss/accuracy curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uln6djjEBSN2"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_fedavg(\n",
    "    model_ctor,\n",
    "    client_loaders,\n",
    "    test_loader,\n",
    "    *,\n",
    "    device,\n",
    "    rounds=20,\n",
    "    local_epochs=1,\n",
    "    fraction=0.1,\n",
    "    local_lr=0.01,\n",
    "    criterion=None,\n",
    "    seed=42,\n",
    "    log_level=logging.INFO,\n",
    "):\n",
    "\n",
    "    # print(\"train\")\n",
    "    logging.basicConfig(level=log_level, format=\"%(message)s\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # global model\n",
    "    global_model = model_ctor().to(device)\n",
    "    if criterion is None:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # wrap clients\n",
    "    clients = [\n",
    "        Client(i, ld, device=device, num_epochs=local_epochs, criterion=criterion, lr=local_lr)\n",
    "        for i, ld in enumerate(client_loaders)\n",
    "    ]\n",
    "\n",
    "    history = {\"round\": [], \"loss\": [], \"acc\": []}\n",
    "\n",
    "    for r in range(1, rounds + 1):\n",
    "        # print(\"round\")\n",
    "        # sample & broadcast\n",
    "        ids = sample_clients(len(clients), fraction, rng)\n",
    "        for i in ids:\n",
    "            clients[i].x = global_model  # reference (they deepcopy inside)\n",
    "\n",
    "        # local updates\n",
    "        for i in ids:\n",
    "            clients[i].client_update()\n",
    "\n",
    "        # aggregate\n",
    "        fedavg_aggregate(global_model, [clients[i].y for i in ids], device=device)\n",
    "\n",
    "        # evaluate\n",
    "        test_loss, test_acc = evaluate_fn(test_loader, global_model, criterion, device)\n",
    "        history[\"round\"].append(r); history[\"loss\"].append(test_loss); history[\"acc\"].append(test_acc)\n",
    "        logging.info(f\"Round {r:03d} | test loss: {test_loss:.4f} | test acc: {test_acc:.2f}%\")\n",
    "        print(f\"Round {r:03d} | test loss: {test_loss:.4f} | test acc: {test_acc:.2f}%\")\n",
    "\n",
    "    return global_model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAL90PGyB25l"
   },
   "source": [
    "# Run Experiment\n",
    "\n",
    "This section sets experiment hyperparameters and executes the pipeline end-to-end.\n",
    "\n",
    "Key knobs:\n",
    "- `num_clients`: number of simulated clients\n",
    "- `non_iid_per`: degree of label skew across clients\n",
    "- `rounds`: number of FL rounds\n",
    "- `local_epochs`: how long each client trains per round\n",
    "- `fraction`: percentage of clients participating per round\n",
    "- `local_lr`: client learning rate\n",
    "\n",
    "Suggested experiments:\n",
    "1. Fix everything, sweep `non_iid_per` (0 → 1) and compare curves.\n",
    "2. Increase `local_epochs` and observe whether skew causes more client drift.\n",
    "3. Change `fraction` (e.g., 0.1 vs 0.5) and compare stability/convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MNhZvlRsxwU6",
    "outputId": "c0bcbee3-f77f-4703-cac6-051849317614"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 138MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 14.4MB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 44.9MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.54MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST downloaded to: /home/ahoop004/T3-Ciders-FL/2_IID_Concepts/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 001 | test loss: 1.4681 | test acc: 57.74%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 001 | test loss: 1.4681 | test acc: 57.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 002 | test loss: 0.5020 | test acc: 84.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 002 | test loss: 0.5020 | test acc: 84.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 003 | test loss: 0.7259 | test acc: 75.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 003 | test loss: 0.7259 | test acc: 75.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 004 | test loss: 0.6772 | test acc: 78.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 004 | test loss: 0.6772 | test acc: 78.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 005 | test loss: 0.5084 | test acc: 81.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 005 | test loss: 0.5084 | test acc: 81.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 006 | test loss: 1.0009 | test acc: 69.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 006 | test loss: 1.0009 | test acc: 69.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 007 | test loss: 0.3791 | test acc: 88.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 007 | test loss: 0.3791 | test acc: 88.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 008 | test loss: 0.3841 | test acc: 87.39%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 008 | test loss: 0.3841 | test acc: 87.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 009 | test loss: 0.3543 | test acc: 88.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 009 | test loss: 0.3543 | test acc: 88.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 010 | test loss: 0.3273 | test acc: 89.87%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 010 | test loss: 0.3273 | test acc: 89.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 011 | test loss: 0.2175 | test acc: 93.51%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 011 | test loss: 0.2175 | test acc: 93.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 012 | test loss: 0.2556 | test acc: 91.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 012 | test loss: 0.2556 | test acc: 91.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 013 | test loss: 0.2572 | test acc: 92.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 013 | test loss: 0.2572 | test acc: 92.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 014 | test loss: 0.2370 | test acc: 92.26%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 014 | test loss: 0.2370 | test acc: 92.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 015 | test loss: 0.2689 | test acc: 91.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 015 | test loss: 0.2689 | test acc: 91.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 016 | test loss: 0.2019 | test acc: 93.73%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 016 | test loss: 0.2019 | test acc: 93.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 017 | test loss: 0.2724 | test acc: 90.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 017 | test loss: 0.2724 | test acc: 90.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 018 | test loss: 0.1938 | test acc: 93.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 018 | test loss: 0.1938 | test acc: 93.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 019 | test loss: 0.1769 | test acc: 94.51%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 019 | test loss: 0.1769 | test acc: 94.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 020 | test loss: 0.2238 | test acc: 93.02%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 020 | test loss: 0.2238 | test acc: 93.02%\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_root = \"./data\"\n",
    "num_clients = 10\n",
    "batch_size = 64\n",
    "non_iid_per = 0.5     # 0 = IID, 1 = very non-IID\n",
    "rounds = 20\n",
    "local_epochs = 1\n",
    "fraction = 0.2         # 20% clients per round\n",
    "local_lr = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Data\n",
    "download_mnist(data_root)\n",
    "train_ds, test_ds = load_mnist_with_transforms(data_root)\n",
    "client_loaders, test_loader = make_client_loaders(\n",
    "    train_ds, test_ds, num_clients=num_clients,\n",
    "    batch_size=batch_size, non_iid_per=non_iid_per, seed=seed\n",
    ")\n",
    "\n",
    "# Train\n",
    "global_model, history = train_fedavg(\n",
    "    Net, client_loaders, test_loader,\n",
    "    device=device, rounds=rounds, local_epochs=local_epochs,\n",
    "    fraction=fraction, local_lr=local_lr, criterion=criterion, seed=seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweep experiment: vary `non_iid_per` and collect results\n",
    "\n",
    "This cell runs the full FL pipeline multiple times to compare different non-IID strengths:\n",
    "\n",
    "- Sweeps `non_iid_per ∈ {0.10, 0.25, 0.50, 0.75, 0.90}`\n",
    "- For each value:\n",
    "  1. Re-builds client datasets/loaders using that non-IID setting\n",
    "  2. Computes a per-client label count matrix (clients × classes)\n",
    "  3. Trains FedAvg and records the per-round `history`\n",
    "  4. Stores everything in `sweep_results[non_iid_per]`\n",
    "\n",
    "**Output object:** `sweep_results`  \n",
    "Contains:\n",
    "- `history`: global loss/accuracy vs round\n",
    "- `label_counts`: client label distribution matrix (for visualization)\n",
    "- `global_model`: final model for that sweep setting\n",
    "\n",
    "Note: this can take time on HPC; reduce `rounds`, `num_clients`, or skip label counting if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep values you requested\n",
    "non_iid_sweep = [0.10, 0.25, 0.50, 0.75, 0.90]\n",
    "\n",
    "# Use existing notebook hyperparams if they exist, otherwise fall back\n",
    "seed         = globals().get(\"seed\", 42)\n",
    "num_clients  = globals().get(\"num_clients\", 10)\n",
    "batch_size   = globals().get(\"batch_size\", 64)\n",
    "rounds       = globals().get(\"rounds\", 20)\n",
    "local_epochs = globals().get(\"local_epochs\", 1)\n",
    "fraction     = globals().get(\"fraction\", 0.2)\n",
    "local_lr     = globals().get(\"local_lr\", 0.01)\n",
    "device       = globals().get(\"device\", \"cpu\")\n",
    "criterion    = globals().get(\"criterion\", None)\n",
    "\n",
    "data_root = globals().get(\"data_root\", \"./data\")\n",
    "\n",
    "# Storage\n",
    "sweep_results = {}   # maps non_iid_per -> {\"history\":..., \"label_counts\":...}\n",
    "\n",
    "def label_count_from_indices(targets, client_idxs, num_classes=10):\n",
    "    \"\"\"Fast counts: build a [num_clients, num_classes] matrix from split indices (no DataLoader iteration).\"\"\"\n",
    "    if hasattr(targets, \"detach\"):\n",
    "        t = targets.detach().cpu().numpy()\n",
    "    else:\n",
    "        t = np.asarray(targets)\n",
    "\n",
    "    counts = np.zeros((len(client_idxs), num_classes), dtype=int)\n",
    "    for ci, idxs in enumerate(client_idxs):\n",
    "        idxs = np.asarray(idxs, dtype=int)\n",
    "        counts[ci] = np.bincount(t[idxs], minlength=num_classes)\n",
    "    return counts\n",
    "\n",
    "for non_iid_per in non_iid_sweep:\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Data + client loaders\n",
    "    train_ds, test_ds = load_mnist_with_transforms(data_root)\n",
    "    client_loaders, test_loader, client_idxs = make_client_loaders(\n",
    "        train_ds, test_ds,\n",
    "        num_clients=num_clients,\n",
    "        batch_size=batch_size,\n",
    "        non_iid_per=non_iid_per,\n",
    "        seed=seed,\n",
    "        return_indices=True\n",
    "    )\n",
    "\n",
    "    # Label distribution snapshot (clients x classes)\n",
    "    targets = train_ds.targets if hasattr(train_ds, \"targets\") else train_ds.labels\n",
    "    counts = label_count_from_indices(targets, client_idxs, num_classes=10)\n",
    "\n",
    "    # Train\n",
    "    global_model, history = train_fedavg(\n",
    "        Net, client_loaders, test_loader,\n",
    "        device=device,\n",
    "        rounds=rounds,\n",
    "        local_epochs=local_epochs,\n",
    "        fraction=fraction,\n",
    "        local_lr=local_lr,\n",
    "        criterion=criterion,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    sweep_results[non_iid_per] = {\n",
    "        \"history\": history,\n",
    "        \"label_counts\": counts,\n",
    "        \"global_model\": global_model,\n",
    "    }\n",
    "\n",
    "print(\"Done. Keys:\", list(sweep_results.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot comparison: client distributions + training curves\n",
    "\n",
    "This cell visualizes two things for each `non_iid_per` in the sweep:\n",
    "\n",
    "1. **Client label distributions (heatmaps)**  \n",
    "   - Rows: clients  \n",
    "   - Columns: classes (digits 0–9)  \n",
    "   - Color intensity: number of samples  \n",
    "   This shows how skewed each client’s data is.\n",
    "\n",
    "2. **Training results across rounds (overlay plots)**  \n",
    "   - Global **Accuracy vs Round** (one line per `non_iid_per`)\n",
    "   - Global **Loss vs Round** (one line per `non_iid_per`)\n",
    "\n",
    "These plots make it easy to see how increasing non-IID skew changes convergence speed and final performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNm3JlfkGroT"
   },
   "outputs": [],
   "source": [
    "\n",
    "def _get_hist(history, key_candidates):\n",
    "    for k in key_candidates:\n",
    "        if isinstance(history, dict) and k in history:\n",
    "            return np.array(history[k])\n",
    "    raise KeyError(f\"History missing keys {key_candidates}. Available: {list(history.keys()) if isinstance(history, dict) else type(history)}\")\n",
    "\n",
    "# 1) Plot label distributions (heatmap per sweep value)\n",
    "for non_iid_per, pack in sweep_results.items():\n",
    "    counts = pack[\"label_counts\"]  # shape [num_clients, 10]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(counts, aspect=\"auto\")\n",
    "    plt.colorbar(label=\"samples\")\n",
    "    plt.xlabel(\"Class (digit)\")\n",
    "    plt.ylabel(\"Client index\")\n",
    "    plt.title(f\"Client label distribution (non_iid_per={non_iid_per})\")\n",
    "    plt.xticks(range(10))\n",
    "    plt.show()\n",
    "\n",
    "# 2) Plot accuracy vs round (all sweeps on one plot)\n",
    "plt.figure()\n",
    "for non_iid_per, pack in sweep_results.items():\n",
    "    h = pack[\"history\"]\n",
    "    rounds_arr = _get_hist(h, [\"round\", \"rounds\", \"global_round\"])\n",
    "    acc_arr    = _get_hist(h, [\"acc\", \"accuracy\", \"test_acc\", \"global_acc\"])\n",
    "    plt.plot(rounds_arr, acc_arr, marker=\"o\", label=f\"{non_iid_per}\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Global Accuracy vs Round (sweep over non_iid_per)\")\n",
    "plt.grid(True)\n",
    "plt.legend(title=\"non_iid_per\")\n",
    "plt.show()\n",
    "\n",
    "# 3) Plot loss vs round (all sweeps on one plot)\n",
    "plt.figure()\n",
    "for non_iid_per, pack in sweep_results.items():\n",
    "    h = pack[\"history\"]\n",
    "    rounds_arr = _get_hist(h, [\"round\", \"rounds\", \"global_round\"])\n",
    "    loss_arr   = _get_hist(h, [\"loss\", \"test_loss\", \"global_loss\"])\n",
    "    plt.plot(rounds_arr, loss_arr, marker=\"o\", label=f\"{non_iid_per}\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Global Loss vs Round (sweep over non_iid_per)\")\n",
    "plt.grid(True)\n",
    "plt.legend(title=\"non_iid_per\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
