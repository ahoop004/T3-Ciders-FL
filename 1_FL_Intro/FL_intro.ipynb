{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYjvZ3vMyaTZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 — Federated Learning (FL) Intro: From Centralized Training to FedAvg\n",
    "\n",
    "This notebook is a hands-on walkthrough of the *minimum working pipeline* for Federated Learning:\n",
    "- what changes relative to centralized ML,\n",
    "- how client data is split,\n",
    "- how local training works,\n",
    "- how the server aggregates updates (FedAvg),\n",
    "- and how we evaluate a global model over multiple rounds.\n",
    "\n",
    "**Output:** a trained *global model* and plots showing training progress across FL rounds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this notebook you should be able to:\n",
    "1. Explain the difference between *centralized* training and *federated* training.\n",
    "2. Describe the 5-step FL loop (select clients → send model → local train → aggregate → repeat).\n",
    "3. Implement a simple FedAvg round using multiple clients.\n",
    "4. Evaluate a global model and interpret accuracy/loss curves across rounds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We import:\n",
    "- **PyTorch** for models, training, and tensors,\n",
    "- **torchvision** for datasets and transforms,\n",
    "- **NumPy** for light data manipulation,\n",
    "- **matplotlib** for visualization.\n",
    "\n",
    "As you read the code, focus on *where FL logic begins*—the parts that simulate multiple clients and aggregation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 10337,
     "status": "ok",
     "timestamp": 1755704007041,
     "user": {
      "displayName": "Aaron HOOPER",
      "userId": "06595748364739258750"
     },
     "user_tz": 240
    },
    "id": "qSc48na9xwU1"
   },
   "outputs": [],
   "source": [
    "import os, math, random, logging\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "\n",
    "We set random seeds so that:\n",
    "- dataset splits across clients are repeatable,\n",
    "- training results are easier to compare across runs,\n",
    "- and debugging is less painful.\n",
    "\n",
    "Note: exact reproducibility can still vary across GPU/CPU and library versions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1755704409859,
     "user": {
      "displayName": "Aaron HOOPER",
      "userId": "06595748364739258750"
     },
     "user_tz": 240
    },
    "id": "0ynDNrMX2lHC"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHp9u4z3yzVV"
   },
   "source": [
    "## Model: a small CNN for MNIST\n",
    "\n",
    "All clients train the **same model architecture**.\n",
    "\n",
    "Federated Learning does not require a special model; the key change is *how training is coordinated*.\n",
    "\n",
    "In each round:\n",
    "- The server sends the current global weights to clients.\n",
    "- Clients train locally on their private data.\n",
    "- The server aggregates client updates into a new global model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1755704495885,
     "user": {
      "displayName": "Aaron HOOPER",
      "userId": "06595748364739258750"
     },
     "user_tz": 240
    },
    "id": "DzzFl90vyw6Q"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool  = nn.MaxPool2d(2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(64 * 14 * 14, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETow0Pm1y5q_"
   },
   "source": [
    "## Dataset overview\n",
    "\n",
    "We use a standard vision dataset so we can focus on the *federated process* instead of domain-specific data cleaning.\n",
    "\n",
    "Key idea:\n",
    "- In centralized ML: all data is available in one place.\n",
    "- In FL: data is partitioned across many clients (devices/organizations) and **does not move** to the server.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1755704496190,
     "user": {
      "displayName": "Aaron HOOPER",
      "userId": "06595748364739258750"
     },
     "user_tz": 240
    },
    "id": "bHPNyR4MyxAx"
   },
   "outputs": [],
   "source": [
    "def download_mnist(root=\"./data\"):\n",
    "\n",
    "    _ = datasets.MNIST(root=root, train=True,  download=True)\n",
    "    _ = datasets.MNIST(root=root, train=False, download=True)\n",
    "    print(f\"MNIST downloaded to: {os.path.abspath(root)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBy2LzPqy_jB"
   },
   "source": [
    "## Data preprocessing and transforms\n",
    "\n",
    "We convert images to tensors and normalize them so training is stable and comparable across clients.\n",
    "\n",
    "Typical transform components:\n",
    "- `ToTensor()` scales pixel values to `[0, 1]`.\n",
    "- `Normalize(mean, std)` standardizes the input distribution.\n",
    "\n",
    "All clients should use the same preprocessing for a clean baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1755704496420,
     "user": {
      "displayName": "Aaron HOOPER",
      "userId": "06595748364739258750"
     },
     "user_tz": 240
    },
    "id": "8eeG9in0yxER"
   },
   "outputs": [],
   "source": [
    "def mnist_transforms():\n",
    "\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "def load_mnist_with_transforms(root=\"./data\", transform=None):\n",
    "\n",
    "    if transform is None:\n",
    "        transform = mnist_transforms()\n",
    "    train_ds = datasets.MNIST(root=root, train=True,  download=False, transform=transform)\n",
    "    test_ds  = datasets.MNIST(root=root, train=False, download=False, transform=transform)\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOpndWXuzIK7"
   },
   "source": [
    "## Distributing data across clients\n",
    "\n",
    "We simulate **multiple clients** by partitioning the training dataset into per-client subsets.\n",
    "\n",
    "Two common modes are supported:\n",
    "- **IID**: each client receives a random slice of the dataset (similar class distribution).\n",
    "- **Non-IID**: each client receives a skewed distribution (some classes dominate per client).\n",
    "\n",
    "In this intro module, we start with IID (or mild non-IID) so the FedAvg loop is easier to validate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1755704496729,
     "user": {
      "displayName": "Aaron HOOPER",
      "userId": "06595748364739258750"
     },
     "user_tz": 240
    },
    "id": "4EIs0hHjyxGo"
   },
   "outputs": [],
   "source": [
    "def _iid_indices(n_items, num_clients, seed=42):\n",
    "    # print(\"iid\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(n_items)\n",
    "    rng.shuffle(idx)\n",
    "    splits = np.array_split(idx, num_clients)\n",
    "    return [np.array(s, dtype=int) for s in splits]\n",
    "\n",
    "def _dirichlet_label_skew_indices(targets, num_clients, alpha=0.5, seed=42):\n",
    "\n",
    "    # print(\"skew\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "    targets = np.asarray(targets)\n",
    "    classes = np.unique(targets)\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "\n",
    "    for c in classes:\n",
    "        c_idx = np.where(targets == c)[0]\n",
    "        rng.shuffle(c_idx)\n",
    "\n",
    "        props = rng.dirichlet([alpha] * num_clients)\n",
    "\n",
    "        counts = (len(c_idx) * props).astype(int)\n",
    "\n",
    "        while counts.sum() < len(c_idx):\n",
    "            counts[np.argmax(props)] += 1\n",
    "\n",
    "        start = 0\n",
    "        for i, cnt in enumerate(counts):\n",
    "            if cnt > 0:\n",
    "                client_indices[i].extend(c_idx[start:start+cnt])\n",
    "                start += cnt\n",
    "\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        client_indices[i] = np.array(client_indices[i], dtype=int)\n",
    "        rng.shuffle(client_indices[i])\n",
    "    return client_indices\n",
    "\n",
    "def make_client_loaders(\n",
    "    train_ds,\n",
    "    test_ds,\n",
    "    num_clients=10,\n",
    "    batch_size=64,\n",
    "    non_iid_per=0.0,\n",
    "    seed=42,\n",
    "):\n",
    "\n",
    "    if non_iid_per <= 1e-8:\n",
    "        client_idxs = _iid_indices(len(train_ds), num_clients, seed=seed)\n",
    "    else:\n",
    "\n",
    "        alpha = max(0.01, 1.0 - 0.99 * non_iid_per)\n",
    "        targets = train_ds.targets if hasattr(train_ds, \"targets\") else train_ds.labels\n",
    "        client_idxs = _dirichlet_label_skew_indices(targets, num_clients, alpha=alpha, seed=seed)\n",
    "\n",
    "    local_loaders = [\n",
    "        DataLoader(Subset(train_ds, idxs), batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "        for idxs in client_idxs\n",
    "    ]\n",
    "    test_loader = DataLoader(test_ds, batch_size=512, shuffle=False, drop_last=False)\n",
    "    return local_loaders, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuTz4veEs5gx"
   },
   "source": [
    "## Federated Averaging (FedAvg): client updates + server aggregation\n",
    "\n",
    "FedAvg is the simplest baseline FL algorithm.\n",
    "\n",
    "High-level flow per round:\n",
    "1. Sample a subset of clients.\n",
    "2. Broadcast the current global model to those clients.\n",
    "3. Each client trains locally for a small number of epochs.\n",
    "4. The server averages client models (often weighted by client dataset size).\n",
    "5. Evaluate the updated global model on a shared test set.\n",
    "\n",
    "This establishes a baseline you can compare against later modules (non-IID, attacks, defenses).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client object: local training on private data\n",
    "\n",
    "Each client holds:\n",
    "- its own private dataset (a DataLoader),\n",
    "- local hyperparameters like local epochs and learning rate,\n",
    "- two model references: a local copy to train and a way to receive updated global weights.\n",
    "\n",
    "The client never sends raw data to the server—only model parameters (or parameter differences).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1755704496962,
     "user": {
      "displayName": "Aaron HOOPER",
      "userId": "06595748364739258750"
     },
     "user_tz": 240
    },
    "id": "QdWuIMZhxwU3"
   },
   "outputs": [],
   "source": [
    "class Client():\n",
    "\n",
    "    def __init__(self, client_id, local_data, device, num_epochs, criterion, lr):\n",
    "        self.id = client_id\n",
    "        self.data = local_data\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.num_epochs = num_epochs\n",
    "        self.lr = lr\n",
    "        self.criterion = criterion\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    def client_update(self):\n",
    "        # print(\"update\")\n",
    "\n",
    "\n",
    "        self.y = deepcopy(self.x)\n",
    "        self.y.to(self.device)\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "\n",
    "            for inputs,labels in self.data:\n",
    "              inputs, labels = inputs.float().to(self.device), labels.long().to(self.device)\n",
    "              output = self.y(inputs)\n",
    "              loss = self.criterion(output, labels)\n",
    "              grads = torch.autograd.grad(loss,self.y.parameters())\n",
    "\n",
    "              with torch.no_grad():\n",
    "                  for param,grad in zip(self.y.parameters(),grads):\n",
    "                      param.data = param.data - self.lr * grad.data\n",
    "\n",
    "              if self.device == \"cuda\": torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server-side utilities: evaluation, sampling, aggregation, and history\n",
    "\n",
    "Server-side responsibilities in this notebook:\n",
    "- `test_model(...)`: computes loss and accuracy on the shared test set.\n",
    "- `sample_clients(...)`: selects a subset of clients each round (to mimic partial participation).\n",
    "- `FedAvg(...)`: aggregates client models into a new global model.\n",
    "- `history`: stores metrics by round so we can plot progress.\n",
    "\n",
    "These utilities make the training loop easier to read and debug.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1755704497096,
     "user": {
      "displayName": "Aaron HOOPER",
      "userId": "06595748364739258750"
     },
     "user_tz": 240
    },
    "id": "e_zmWJo9xwU3"
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample_clients(num_clients, fraction, rng):\n",
    "    k = max(1, int(math.ceil(fraction * num_clients)))\n",
    "    return sorted(rng.choice(np.arange(num_clients), size=k, replace=False).tolist())\n",
    "\n",
    "def fedavg_aggregate(global_model, client_models, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # init accumulators\n",
    "        acc = [torch.zeros_like(p, device=device) for p in global_model.parameters()]\n",
    "        for cm in client_models:\n",
    "            for a, p in zip(acc, cm.parameters()):\n",
    "                a.add_(p.to(device))\n",
    "        for gp, a in zip(global_model.parameters(), acc):\n",
    "            gp.copy_(a / len(client_models))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_fedavg(\n",
    "    model_ctor,\n",
    "    client_loaders,\n",
    "    test_loader,\n",
    "    *,\n",
    "    device,\n",
    "    rounds=20,\n",
    "    local_epochs=1,\n",
    "    fraction=0.1,\n",
    "    local_lr=0.01,\n",
    "    criterion=None,\n",
    "    seed=42,\n",
    "    log_level=logging.INFO,\n",
    "):\n",
    "\n",
    "    # print(\"train\")\n",
    "    logging.basicConfig(level=log_level, format=\"%(message)s\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # global model\n",
    "    global_model = model_ctor().to(device)\n",
    "    if criterion is None:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # wrap clients\n",
    "    clients = [\n",
    "        Client(i, ld, device=device, num_epochs=local_epochs, criterion=criterion, lr=local_lr)\n",
    "        for i, ld in enumerate(client_loaders)\n",
    "    ]\n",
    "\n",
    "    history = {\"round\": [], \"loss\": [], \"acc\": []}\n",
    "\n",
    "    for r in range(1, rounds + 1):\n",
    "        # print(\"round\")\n",
    "        # sample & broadcast\n",
    "        ids = sample_clients(len(clients), fraction, rng)\n",
    "        for i in ids:\n",
    "            clients[i].x = global_model  # reference (they deepcopy inside)\n",
    "\n",
    "        # local updates\n",
    "        for i in ids:\n",
    "            clients[i].client_update()\n",
    "\n",
    "        # aggregate\n",
    "        fedavg_aggregate(global_model, [clients[i].y for i in ids], device=device)\n",
    "\n",
    "        # evaluate\n",
    "        test_loss, test_acc = evaluate_fn(test_loader, global_model, criterion, device)\n",
    "        history[\"round\"].append(r); history[\"loss\"].append(test_loss); history[\"acc\"].append(test_acc)\n",
    "        logging.info(f\"Round {r:03d} | test loss: {test_loss:.4f} | test acc: {test_acc:.2f}%\")\n",
    "        print(f\"Round {r:03d} | test loss: {test_loss:.4f} | test acc: {test_acc:.2f}%\")\n",
    "\n",
    "    return global_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fn(test_loader, model, criterion, device):\n",
    "    # print(\"eval\")\n",
    "    model.eval()\n",
    "    n, total_loss, correct = 0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device, dtype=torch.float)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            pred = logits.argmax(dim=1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            n += x.size(0)\n",
    "    return (total_loss / max(1, n)), (100.0 * correct / max(1, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment configuration and running training\n",
    "\n",
    "Here we set:\n",
    "- the number of clients,\n",
    "- client batch size,\n",
    "- IID vs non-IID split strength (`non_iid_per`),\n",
    "- FL rounds, local epochs, and the fraction of clients per round.\n",
    "\n",
    "Then we:\n",
    "1. download/load MNIST,\n",
    "2. create per-client data loaders,\n",
    "3. run FedAvg training and collect metrics in `history`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 100947,
     "status": "ok",
     "timestamp": 1755704598125,
     "user": {
      "displayName": "Aaron HOOPER",
      "userId": "06595748364739258750"
     },
     "user_tz": 240
    },
    "id": "MNhZvlRsxwU6",
    "outputId": "2a360fcf-4000-44d5-f392-7bb4a785d6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST downloaded to: /content/data\n",
      "round\n",
      "Round 001 | test loss: 0.6342 | test acc: 83.18%\n",
      "round\n",
      "Round 002 | test loss: 0.3816 | test acc: 88.16%\n",
      "round\n",
      "Round 003 | test loss: 0.3553 | test acc: 89.10%\n",
      "round\n",
      "Round 004 | test loss: 0.2917 | test acc: 91.24%\n",
      "round\n",
      "Round 005 | test loss: 0.2710 | test acc: 92.01%\n",
      "round\n",
      "Round 006 | test loss: 0.2376 | test acc: 92.90%\n",
      "round\n",
      "Round 007 | test loss: 0.2315 | test acc: 92.98%\n",
      "round\n",
      "Round 008 | test loss: 0.2298 | test acc: 92.87%\n",
      "round\n",
      "Round 009 | test loss: 0.1945 | test acc: 94.08%\n",
      "round\n",
      "Round 010 | test loss: 0.1803 | test acc: 94.42%\n",
      "round\n",
      "Round 011 | test loss: 0.1762 | test acc: 94.64%\n",
      "round\n",
      "Round 012 | test loss: 0.1821 | test acc: 94.08%\n",
      "round\n",
      "Round 013 | test loss: 0.1626 | test acc: 95.05%\n",
      "round\n",
      "Round 014 | test loss: 0.1461 | test acc: 95.68%\n",
      "round\n",
      "Round 015 | test loss: 0.1427 | test acc: 95.72%\n",
      "round\n",
      "Round 016 | test loss: 0.1366 | test acc: 96.00%\n",
      "round\n",
      "Round 017 | test loss: 0.1408 | test acc: 95.76%\n",
      "round\n",
      "Round 018 | test loss: 0.1362 | test acc: 95.96%\n",
      "round\n",
      "Round 019 | test loss: 0.1458 | test acc: 95.66%\n",
      "round\n",
      "Round 020 | test loss: 0.1316 | test acc: 95.93%\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_root = \"./data\"\n",
    "num_clients = 10\n",
    "batch_size = 64\n",
    "non_iid_per = 0.0      # 0 = IID, 1 = very non-IID\n",
    "rounds = 20\n",
    "local_epochs = 1\n",
    "fraction = 0.2         # 20% clients per round\n",
    "local_lr = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Data\n",
    "download_mnist(data_root)\n",
    "train_ds, test_ds = load_mnist_with_transforms(data_root)\n",
    "client_loaders, test_loader = make_client_loaders(\n",
    "    train_ds, test_ds, num_clients=num_clients,\n",
    "    batch_size=batch_size, non_iid_per=non_iid_per, seed=seed\n",
    ")\n",
    "\n",
    "# Train\n",
    "global_model, history = train_fedavg(\n",
    "    Net, client_loaders, test_loader,\n",
    "    device=device, rounds=rounds, local_epochs=local_epochs,\n",
    "    fraction=fraction, local_lr=local_lr, criterion=criterion, seed=seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps \n",
    "\n",
    "- Plot `history[\"acc\"]` and `history[\"loss\"]` versus `history[\"round\"]`.\n",
    "- Save the trained `global_model` checkpoint for later modules.\n",
    "- Try changing one knob at a time (clients, local epochs, fraction, non-IID) and compare curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1755704598143,
     "user": {
      "displayName": "Aaron HOOPER",
      "userId": "06595748364739258750"
     },
     "user_tz": 240
    },
    "id": "zNm3JlfkGroT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _get_first_key(d, keys):\n",
    "    for k in keys:\n",
    "        if k in d:\n",
    "            return k\n",
    "    raise KeyError(f\"None of these keys found in history: {keys}. Available keys: {list(d.keys())}\")\n",
    "\n",
    "# Adjust these if your notebook uses different names\n",
    "round_key = _get_first_key(history, [\"round\", \"rounds\", \"r\", \"epoch\", \"global_round\"])\n",
    "acc_key   = _get_first_key(history, [\"acc\", \"accuracy\", \"test_acc\", \"global_acc\"])\n",
    "loss_key  = _get_first_key(history, [\"loss\", \"test_loss\", \"global_loss\"])\n",
    "\n",
    "rounds = np.array(history[round_key])\n",
    "acc    = np.array(history[acc_key])\n",
    "loss   = np.array(history[loss_key])\n",
    "\n",
    "# Accuracy vs Round\n",
    "plt.figure()\n",
    "plt.plot(rounds, acc, marker=\"o\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Global Accuracy vs Round\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Loss vs Round\n",
    "plt.figure()\n",
    "plt.plot(rounds, loss, marker=\"o\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Global Loss vs Round\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Choose a location that works well on ODU HPC\n",
    "save_dir = os.environ.get(\"FD_learning\", \".\")\n",
    "save_path = os.path.join(save_dir, \"t3fl_global_model.pt\")\n",
    "\n",
    "# Prefer saving state_dict (portable, standard)\n",
    "ckpt = {\n",
    "    \"model_state_dict\": global_model.state_dict(),\n",
    "    # Optional but useful:\n",
    "    \"round\": history.get(\"round\", None) if isinstance(history, dict) else None,\n",
    "    \"history\": history if isinstance(history, dict) else None,\n",
    "    # \"config\": config_dict,  # uncomment if you have one\n",
    "}\n",
    "\n",
    "torch.save(ckpt, save_path)\n",
    "print(f\"Saved checkpoint to: {save_path}\")\n",
    "\n",
    "# --- Loading later (example) ---\n",
    "# global_model = Net()  # re-create the same model class/architecture first\n",
    "# ckpt = torch.load(save_path, map_location=\"cpu\")\n",
    "# global_model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "# global_model.eval()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
